{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Create a New Folder or Python File in VS Code\n",
    "* Open VS Code. Create a new folder from VC Code (or using the Finder as well). In VS Code, now we open File > Open Folder and select the newly created folder (e.g. counterspeech-models). We can now create a new Python file within this folder by clicking New File icon and naming. Let's say models.py.\n",
    "#### Step 2: Create a Virtual Environment\n",
    "* Open New Terminal within VS Code. First, check we are in the correct directory using Terminal (bash): cd /Users/tonigamundi/Desktop/Counterspeech-Amalia/\n",
    "* Create a virtual environment called counterspeech in the bash as well: python3 -m venv counterspeech (This command will create a virtual environment named counterspeech in the current directory.)\n",
    "#### Step 3: Activate the Virtual Environment\n",
    "* Activate the virtual environment in the bash: source /Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/bin/activate\n",
    "* We should see the environment name (counterspeech) appear in the terminal, indicating the virtual environment is active.\n",
    "#### Step 4: Install Required Packages\n",
    "* Install Jupyter and all required libraries if needed in the bash: pip install jupyter imbalanced-learn scikit-learn\n",
    "* Now verify that the libraries were installed correctly in the bash: pip list\n",
    "#### Step 5: Add Virtual Environment to Jupyter as a Kernel\n",
    "* To make the virtual environment available in Jupyter Notebook, install ipykernel in the bash: pip install ipykernel\n",
    "* Now, register the virtual environment as a Jupyter kernel: python -m ipykernel install --user --name counterspeech --display-name \"Python (counterspeech)\" (this command will add the environment as a Jupyter kernel named \"Python (counterspeech)\".)\n",
    "#### Step 6: Open Jupyter Notebook in VS Code\n",
    "* Create a Jupyter notebook in VS Code. In VS Code, click on the New File icon and create a new file with the extension .ipynb (e.g. models_analysis.ipynb).\n",
    "* At the top right of the notebook interface, click on the kernel selector (which might say something like Python 3). Select \"Python (counterspeech)\" to ensure that your notebook uses the virtual environment you created.\n",
    "#### Step 7: Verify the Environment in Your Notebook\n",
    "* Verify the Correct Python Environment in a notebook cell: \n",
    "import sys \n",
    "print(sys.executable)\n",
    "* The output should show the path to the Python executable inside your counterspeech environment, such as /Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/bin/python.\n",
    "\n",
    "This will ensure that all packages installed in the virtual environment are available in our Jupyter Notebook.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps if I just want to reopen and activate an environment:\n",
    "\n",
    "#### Step 1: Navigate to the Folder\n",
    "* From VS Code, just open the folder that contains your virtual environment by going to File > Open Folder and selecting the appropriate folder (in your case, /Users/tonigamundi/Desktop/Counterspeech-Amalia/).\n",
    "\n",
    "#### Step 2: Select the Virtual Environment in VS Code (If Using Jupyter Notebooks)\n",
    "When using Jupyter notebooks in VS Code and want to switch to this environment as your kernel, do the following:\n",
    "* Open any .ipynb notebook file or create a new one.\n",
    "* At the top right of the notebook interface, click on the kernel selector (it may say something like Python 3). \n",
    "* Select the \"Python (counterspeech)\" kernel. This ensures that the notebook uses your virtual environment.\n",
    "\n",
    "#### Step 3: Verify the Active Environment\n",
    "\n",
    "To ensure the virtual environment is active, run the following command inside your Python file or Jupyter notebook:\n",
    "\n",
    "`import sys`\n",
    "`print(sys.executable)`\n",
    "\n",
    "This should output something like:\n",
    "\n",
    "bash `/Users/tonigamundi/Desktop/Counterspeech_project/counterspeech/bin/python`\n",
    "\n",
    "This indicates that the virtual environment is correctly activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in ./lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in ./lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Installing collected packages: click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.9.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install all necessary libraries\n",
    "#!pip install pandas scikit-learn numpy imbalanced-learn\n",
    "# After that, make sure to restart the kernel in our Jupyter notebook to ensure that the newly installed libraries are recognized and properly loaded\n",
    "#!pip install  nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) TF-IDF with unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'schwule', 'rechte', 'strasse', 'gehen', 'schoen',\n",
       "       'sehen', 'freiheitsgedanke', 'international', 'fruechte',\n",
       "       ...\n",
       "       'wuetenden', 'maschendraht', 'bildausschnitte', 'pauschalaussagen',\n",
       "       'auserdem', 'allerwenigsten', 'einziges', 'hir', 'garkein', 'counter'],\n",
       "      dtype='object', length=5948)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DFM_tfidf.csv\", sep = \",\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>schwule</th>\n",
       "      <th>rechte</th>\n",
       "      <th>strasse</th>\n",
       "      <th>gehen</th>\n",
       "      <th>schoen</th>\n",
       "      <th>sehen</th>\n",
       "      <th>freiheitsgedanke</th>\n",
       "      <th>international</th>\n",
       "      <th>fruechte</th>\n",
       "      <th>...</th>\n",
       "      <th>wuetenden</th>\n",
       "      <th>maschendraht</th>\n",
       "      <th>bildausschnitte</th>\n",
       "      <th>pauschalaussagen</th>\n",
       "      <th>auserdem</th>\n",
       "      <th>allerwenigsten</th>\n",
       "      <th>einziges</th>\n",
       "      <th>hir</th>\n",
       "      <th>garkein</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.124758</td>\n",
       "      <td>1.516707</td>\n",
       "      <td>1.726818</td>\n",
       "      <td>1.698789</td>\n",
       "      <td>1.601879</td>\n",
       "      <td>1.350646</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.516707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 5948 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   schwule    rechte   strasse     gehen    schoen     sehen  \\\n",
       "0              1  2.124758  1.516707  1.726818  1.698789  1.601879  1.350646   \n",
       "1              2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2              3  0.000000  1.516707  0.000000  0.000000  0.000000  0.000000   \n",
       "3              4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4              5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "2394        2395  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2395        2396  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2396        2397  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2397        2398  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2398        2399  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      freiheitsgedanke  international  fruechte  ...  wuetenden  maschendraht  \\\n",
       "0              3.38003        3.38003   3.38003  ...    0.00000       0.00000   \n",
       "1              0.00000        0.00000   0.00000  ...    0.00000       0.00000   \n",
       "2              0.00000        0.00000   0.00000  ...    0.00000       0.00000   \n",
       "3              0.00000        0.00000   0.00000  ...    0.00000       0.00000   \n",
       "4              0.00000        0.00000   0.00000  ...    0.00000       0.00000   \n",
       "...                ...            ...       ...  ...        ...           ...   \n",
       "2394           0.00000        0.00000   0.00000  ...    0.00000       0.00000   \n",
       "2395           0.00000        0.00000   0.00000  ...    0.00000       0.00000   \n",
       "2396           0.00000        0.00000   0.00000  ...    0.00000       0.00000   \n",
       "2397           0.00000        0.00000   0.00000  ...    3.38003       3.38003   \n",
       "2398           0.00000        0.00000   0.00000  ...    0.00000       0.00000   \n",
       "\n",
       "      bildausschnitte  pauschalaussagen  auserdem  allerwenigsten  einziges  \\\n",
       "0             0.00000           0.00000   0.00000         0.00000   0.00000   \n",
       "1             0.00000           0.00000   0.00000         0.00000   0.00000   \n",
       "2             0.00000           0.00000   0.00000         0.00000   0.00000   \n",
       "3             0.00000           0.00000   0.00000         0.00000   0.00000   \n",
       "4             0.00000           0.00000   0.00000         0.00000   0.00000   \n",
       "...               ...               ...       ...             ...       ...   \n",
       "2394          0.00000           0.00000   0.00000         0.00000   0.00000   \n",
       "2395          0.00000           0.00000   0.00000         0.00000   0.00000   \n",
       "2396          0.00000           0.00000   0.00000         0.00000   0.00000   \n",
       "2397          3.38003           3.38003   0.00000         0.00000   0.00000   \n",
       "2398          0.00000           0.00000   3.38003         3.38003   3.38003   \n",
       "\n",
       "          hir  garkein  counter  \n",
       "0     0.00000  0.00000        0  \n",
       "1     0.00000  0.00000        0  \n",
       "2     0.00000  0.00000        0  \n",
       "3     0.00000  0.00000        0  \n",
       "4     0.00000  0.00000        0  \n",
       "...       ...      ...      ...  \n",
       "2394  0.00000  0.00000        0  \n",
       "2395  0.00000  0.00000        1  \n",
       "2396  0.00000  0.00000        0  \n",
       "2397  0.00000  0.00000        0  \n",
       "2398  3.38003  3.38003        0  \n",
       "\n",
       "[2399 rows x 5948 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Unnamed: 0\",'counter'])  # the features are X\n",
    "\n",
    "y = df['counter'] # the label or target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) # 70/30 and we set seed and stratify the splits by class given the huge imbalance between classes!\n",
    "\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0) \n",
    "# Specifies L1 regularization (Lasso; L2 would be Ridge), which helps in feature selection by encouraging sparsity (some coefficients are set to zero). \n",
    "\n",
    "cv_scores = cross_val_score(logreg_l1, X_train, y_train, cv=10, scoring='accuracy') # CROSS VALIDATION!\n",
    "# It uses 10 folds in the cross-validation process, meaning it splits the training data into 10 parts, trains on 9, and validates on 1, repeating for each fold!\n",
    "\n",
    "# Now let's train the logistic regression on the training data\n",
    "logreg_l1.fit(X_train, y_train)\n",
    "y_pred = logreg_l1.predict(X_test) # Uses the trained model to predict the target variable for the test set!\n",
    "\n",
    "# MODEL PERFORMANCE\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': logreg_l1.coef_[0]\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index) # Sorts the features by the absolute value of their coefficients in descending order\n",
    "\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "\n",
    "print(\"Feature importance has been saved to 'feature_importance1.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes:\n",
    "1) The test set accuracy of 90.97% is slightly lower than the mean cross-validation accuracy (93.03%), which is a sign that the model is not generalizing well to unseen data.\n",
    "2) The high mean accuracy implies that the model is capturing relevant features from the text well, thanks to the TF-IDF feature extraction.\n",
    "Shortcomings:\n",
    "1) The confusion matrix indicates that the model is performing well for the majority class but struggles with the minority class (counterspeech).\n",
    "2) There are only 6 instances correctly classified as negative, which clearly suggests that the **minorty class is underrepresented**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional metrics: Precision, Recall, and F1-Score\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes:\n",
    "1) Precision: Only 26% of the comments predicted as counterspeech were actually counterspeech!\n",
    "2) Recall: Only 11% of actual counterspeech comments were correctly identified by the model, indicating  a high false negative rate.\n",
    "3) F1 score of 16%: Shows that there is a significant imbalance between precision and recall. The low F1-score highlights that the model is struggling with both correctly identifying counterspeech and minimizing false positives.\n",
    "Now, regarding the classification report:\n",
    "1) The model performs extremely well on the \"Not Counterspeech\" class, with high values for precision, recall, and F1-score.\n",
    "2) The precision (0.26), recall (0.11), and F1-score (0.16) for the Counterspeech class are considerably lower compared to the Not Counterspeech class. This shows the model struggles significantly to identify counterspeech comments correctly.\n",
    "In other words -> We should conduct **SMOTE or simple random oversampling (as well as weights)** in order to account for the huge imbalance between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>verurteilen</td>\n",
       "      <td>2.053182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>kleiner</td>\n",
       "      <td>2.047971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>gefaehrlich</td>\n",
       "      <td>1.810060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>verlangt</td>\n",
       "      <td>1.779389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>einsetzt</td>\n",
       "      <td>1.762844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>sachlich</td>\n",
       "      <td>1.735374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>widersprechen</td>\n",
       "      <td>1.642630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>oberflaechlich</td>\n",
       "      <td>1.629797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>griesgram</td>\n",
       "      <td>1.547871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>verstoert</td>\n",
       "      <td>1.527784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>dich</td>\n",
       "      <td>1.465533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>erklaert</td>\n",
       "      <td>1.454055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>kommentare</td>\n",
       "      <td>1.367189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>verbissen</td>\n",
       "      <td>1.334215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>is</td>\n",
       "      <td>1.333329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Coefficient\n",
       "1966     verurteilen     2.053182\n",
       "2750         kleiner     2.047971\n",
       "225      gefaehrlich     1.810060\n",
       "1473        verlangt     1.779389\n",
       "4231        einsetzt     1.762844\n",
       "3064        sachlich     1.735374\n",
       "1422   widersprechen     1.642630\n",
       "1480  oberflaechlich     1.629797\n",
       "3904       griesgram     1.547871\n",
       "2902       verstoert     1.527784\n",
       "3133            dich     1.465533\n",
       "4354        erklaert     1.454055\n",
       "984       kommentare     1.367189\n",
       "422        verbissen     1.334215\n",
       "1257              is     1.333329"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on the importance of features:\n",
    "1) Terms like “widersprechen” (contradict) and “verurteilen” (condemn) reflect the core function of counterspeech, which is to directly challenge and push back against hate speech.\n",
    "2) Words such as “sachlich” (factual) and “erklaert” (explains) indicate a preference for rational, factual responses that aim to correct misinformation and foster a reasoned debate.\n",
    "3) Words like “verstoert” (upset) and “dich” (you) show that counterspeech also engages on a personal and emotional level, often expressing concern, frustration, or directly confronting other individuals.\n",
    "4) Words like “verlangt” (demands) indicate that counterspeech is often proactive, calling for change or action rather than merely reacting passively.\n",
    "\n",
    "* To conclude: it seems that counterspeech has to do with both direct confrontation and rebuttal, emotional appeals, and rational/fact-based discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) TF-IDF with trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'schwule_rechte_strasse', 'rechte_strasse_gehen',\n",
       "       'strasse_gehen_schoen', 'gehen_schoen_sehen',\n",
       "       'schoen_sehen_freiheitsgedanke', 'sehen_freiheitsgedanke_international',\n",
       "       'freiheitsgedanke_international_fruechte',\n",
       "       'international_fruechte_traegt', 'nehme_christopher_street',\n",
       "       ...\n",
       "       'gewalt_user_dies', 'user_dies_deren', 'dies_deren_einziges',\n",
       "       'deren_einziges_kommen', 'einziges_kommen_doch', 'kommen_doch_hir',\n",
       "       'doch_hir_garkein', 'hir_garkein_zaun', 'garkein_zaun_oder', 'counter'],\n",
       "      dtype='object', length=22763)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DFM_tfidf_trigrams.csv\", sep = \",\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>schwule_rechte_strasse</th>\n",
       "      <th>rechte_strasse_gehen</th>\n",
       "      <th>strasse_gehen_schoen</th>\n",
       "      <th>gehen_schoen_sehen</th>\n",
       "      <th>schoen_sehen_freiheitsgedanke</th>\n",
       "      <th>sehen_freiheitsgedanke_international</th>\n",
       "      <th>freiheitsgedanke_international_fruechte</th>\n",
       "      <th>international_fruechte_traegt</th>\n",
       "      <th>nehme_christopher_street</th>\n",
       "      <th>...</th>\n",
       "      <th>gewalt_user_dies</th>\n",
       "      <th>user_dies_deren</th>\n",
       "      <th>dies_deren_einziges</th>\n",
       "      <th>deren_einziges_kommen</th>\n",
       "      <th>einziges_kommen_doch</th>\n",
       "      <th>kommen_doch_hir</th>\n",
       "      <th>doch_hir_garkein</th>\n",
       "      <th>hir_garkein_zaun</th>\n",
       "      <th>garkein_zaun_oder</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>2.902909</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2395</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2396</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2397</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2399</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 22763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  schwule_rechte_strasse  rechte_strasse_gehen  \\\n",
       "0              1                 3.38003              2.902909   \n",
       "1              2                 0.00000              0.000000   \n",
       "2              3                 0.00000              0.000000   \n",
       "3              4                 0.00000              0.000000   \n",
       "4              5                 0.00000              0.000000   \n",
       "...          ...                     ...                   ...   \n",
       "2394        2395                 0.00000              0.000000   \n",
       "2395        2396                 0.00000              0.000000   \n",
       "2396        2397                 0.00000              0.000000   \n",
       "2397        2398                 0.00000              0.000000   \n",
       "2398        2399                 0.00000              0.000000   \n",
       "\n",
       "      strasse_gehen_schoen  gehen_schoen_sehen  schoen_sehen_freiheitsgedanke  \\\n",
       "0                  3.38003             3.38003                        3.38003   \n",
       "1                  0.00000             0.00000                        0.00000   \n",
       "2                  0.00000             0.00000                        0.00000   \n",
       "3                  0.00000             0.00000                        0.00000   \n",
       "4                  0.00000             0.00000                        0.00000   \n",
       "...                    ...                 ...                            ...   \n",
       "2394               0.00000             0.00000                        0.00000   \n",
       "2395               0.00000             0.00000                        0.00000   \n",
       "2396               0.00000             0.00000                        0.00000   \n",
       "2397               0.00000             0.00000                        0.00000   \n",
       "2398               0.00000             0.00000                        0.00000   \n",
       "\n",
       "      sehen_freiheitsgedanke_international  \\\n",
       "0                                  3.38003   \n",
       "1                                  0.00000   \n",
       "2                                  0.00000   \n",
       "3                                  0.00000   \n",
       "4                                  0.00000   \n",
       "...                                    ...   \n",
       "2394                               0.00000   \n",
       "2395                               0.00000   \n",
       "2396                               0.00000   \n",
       "2397                               0.00000   \n",
       "2398                               0.00000   \n",
       "\n",
       "      freiheitsgedanke_international_fruechte  international_fruechte_traegt  \\\n",
       "0                                     3.38003                        3.38003   \n",
       "1                                     0.00000                        0.00000   \n",
       "2                                     0.00000                        0.00000   \n",
       "3                                     0.00000                        0.00000   \n",
       "4                                     0.00000                        0.00000   \n",
       "...                                       ...                            ...   \n",
       "2394                                  0.00000                        0.00000   \n",
       "2395                                  0.00000                        0.00000   \n",
       "2396                                  0.00000                        0.00000   \n",
       "2397                                  0.00000                        0.00000   \n",
       "2398                                  0.00000                        0.00000   \n",
       "\n",
       "      nehme_christopher_street  ...  gewalt_user_dies  user_dies_deren  \\\n",
       "0                      0.00000  ...           0.00000          0.00000   \n",
       "1                      3.38003  ...           0.00000          0.00000   \n",
       "2                      0.00000  ...           0.00000          0.00000   \n",
       "3                      0.00000  ...           0.00000          0.00000   \n",
       "4                      0.00000  ...           0.00000          0.00000   \n",
       "...                        ...  ...               ...              ...   \n",
       "2394                   0.00000  ...           0.00000          0.00000   \n",
       "2395                   0.00000  ...           0.00000          0.00000   \n",
       "2396                   0.00000  ...           0.00000          0.00000   \n",
       "2397                   0.00000  ...           0.00000          0.00000   \n",
       "2398                   0.00000  ...           3.38003          3.38003   \n",
       "\n",
       "      dies_deren_einziges  deren_einziges_kommen  einziges_kommen_doch  \\\n",
       "0                 0.00000                0.00000               0.00000   \n",
       "1                 0.00000                0.00000               0.00000   \n",
       "2                 0.00000                0.00000               0.00000   \n",
       "3                 0.00000                0.00000               0.00000   \n",
       "4                 0.00000                0.00000               0.00000   \n",
       "...                   ...                    ...                   ...   \n",
       "2394              0.00000                0.00000               0.00000   \n",
       "2395              0.00000                0.00000               0.00000   \n",
       "2396              0.00000                0.00000               0.00000   \n",
       "2397              0.00000                0.00000               0.00000   \n",
       "2398              3.38003                3.38003               3.38003   \n",
       "\n",
       "      kommen_doch_hir  doch_hir_garkein  hir_garkein_zaun  garkein_zaun_oder  \\\n",
       "0             0.00000           0.00000           0.00000            0.00000   \n",
       "1             0.00000           0.00000           0.00000            0.00000   \n",
       "2             0.00000           0.00000           0.00000            0.00000   \n",
       "3             0.00000           0.00000           0.00000            0.00000   \n",
       "4             0.00000           0.00000           0.00000            0.00000   \n",
       "...               ...               ...               ...                ...   \n",
       "2394          0.00000           0.00000           0.00000            0.00000   \n",
       "2395          0.00000           0.00000           0.00000            0.00000   \n",
       "2396          0.00000           0.00000           0.00000            0.00000   \n",
       "2397          0.00000           0.00000           0.00000            0.00000   \n",
       "2398          3.38003           3.38003           3.38003            3.38003   \n",
       "\n",
       "      counter  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "2394        0  \n",
       "2395        1  \n",
       "2396        0  \n",
       "2397        0  \n",
       "2398        0  \n",
       "\n",
       "[2399 rows x 22763 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Unnamed: 0\",'counter'])  # the features are X\n",
    "\n",
    "y = df['counter'] # the label or target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y) # 70/30 and we set seed\n",
    "\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0) \n",
    "# Specifies L1 regularization (Lasso; L2 would be Ridge), which helps in feature selection by encouraging sparsity (some coefficients are set to zero). \n",
    "\n",
    "cv_scores = cross_val_score(logreg_l1, X_train, y_train, cv=10, scoring='accuracy') # CROSS VALIDATION!\n",
    "# It uses 10 folds in the cross-validation process, meaning it splits the training data into 10 parts, trains on 9, and validates on 1, repeating for each fold!\n",
    "\n",
    "# Now let's train the logistic regression on the training data\n",
    "logreg_l1.fit(X_train, y_train)\n",
    "y_pred = logreg_l1.predict(X_test) # Uses the trained model to predict the target variable for the test set!\n",
    "\n",
    "# MODEL PERFORMANCE\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': logreg_l1.coef_[0]\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index) # Sorts the features by the absolute value of their coefficients in descending order\n",
    "\n",
    "feature_importance.to_csv('feature_importance2.csv', index=False)\n",
    "\n",
    "print(\"Feature importance has been saved to 'feature_importance2.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional metrics: Precision, Recall, and F1-Score\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) TF-IDF with unigrams with **random oversampling**: Lasso Regression (L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'schwule', 'rechte', 'strasse', 'gehen', 'schoen',\n",
       "       'sehen', 'freiheitsgedanke', 'international', 'fruechte',\n",
       "       ...\n",
       "       'erklaert', 'innerpolitischen', 'konflikten', 'verallgemeinern',\n",
       "       'useralthol', 'userdson', 'problematik', 'bisexuell', 'erstrebenswert',\n",
       "       'counter'],\n",
       "      dtype='object', length=5936)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DFM_tfidf_oversampling.csv\", sep = \",\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.95498392 0.95819936 0.96784566 0.96463023 0.97106109 0.96463023\n",
      " 0.96451613 0.97419355 0.95483871 0.97741935]\n",
      "Mean CV Accuracy: 0.9652318224250596\n",
      "Test Set Accuracy: 0.975975975975976\n",
      "Confusion Matrix on Test Set:\n",
      " [[616  32]\n",
      " [  0 684]]\n",
      "Feature importance has been saved to 'feature_importance3.csv'.\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"Unnamed: 0\",'counter'])  # the features are X\n",
    "\n",
    "y = df['counter'] # the label or target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998) # 70/30 and we set seed\n",
    "\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)\n",
    "# Specifies L1 regularization (Lasso; L2 would be Ridge), which helps in feature selection by encouraging sparsity (some coefficients are set to zero). \n",
    "\n",
    "cv_scores = cross_val_score(logreg_l1, X_train, y_train, cv=10, scoring='accuracy') # CROSS VALIDATION!\n",
    "# It uses 10 folds in the cross-validation process, meaning it splits the training data into 10 parts, trains on 9, and validates on 1, repeating for each fold!\n",
    "\n",
    "# Now let's train the logistic regression on the training data\n",
    "logreg_l1.fit(X_train, y_train)\n",
    "y_pred = logreg_l1.predict(X_test) # Uses the trained model to predict the target variable for the test set!\n",
    "\n",
    "# MODEL PERFORMANCE\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': logreg_l1.coef_[0]\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.reindex(feature_importance.Coefficient.abs().sort_values(ascending=False).index) # Sorts the features by the absolute value of their coefficients in descending order\n",
    "\n",
    "feature_importance.to_csv('feature_importance3.csv', index=False)\n",
    "\n",
    "print(\"Feature importance has been saved to 'feature_importance3.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.96\n",
      "Recall: 1.00\n",
      "F1 Score: 0.98\n",
      "ROC-AUC Score: 0.98\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Not Counterspeech       1.00      0.95      0.97       648\n",
      "    Counterspeech       0.96      1.00      0.98       684\n",
      "\n",
      "         accuracy                           0.98      1332\n",
      "        macro avg       0.98      0.98      0.98      1332\n",
      "     weighted avg       0.98      0.98      0.98      1332\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Predict probabilities for AUC and ROC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "#  Calculate additional metrics: Precision, Recall, and F1-Score\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))\n",
    "\n",
    "# PLOT ROC CURVE\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line (random chance)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways:\n",
    "1)  The narrow range of cross-validation scores suggests the model is not sensitive to different splits of the data, showing robustness in performance.\n",
    "2) Compared to the original results without oversampling, it seems that **random oversampling has improved the model’s performance** due to more balanced class distribution.\n",
    "3) Test Accuracy is very high (97%), indicating that the model performs very (even too much) well on unseen data.\n",
    "4) The model captures **all counterspeech instances without missing any** (Recall = 1.00). This suggests that the model is highly effective in identifying the minority class, which is likely due to the balanced training set achieved by random oversampling. However, the so high accuracy across both cross-validation and the test set suggests a potential **risk of overfitting**, which might limit the model’s performance when exposed to new and different datasets...\n",
    "2) In this case, I applied random oversampling to the whole dataset (i.e. both training and test sets!) but that isn't the common practice. The common practice is to **apply random oversampling ONLY on the training set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.95819936 0.98392283 0.97427653 0.97749196 0.98713826 0.9807074\n",
      " 0.98387097 0.98709677 0.98709677 0.97741935]\n",
      "Mean CV Accuracy: 0.9797220205372886\n",
      "Test Set Accuracy: 0.9041666666666667\n",
      "Confusion Matrix on Test Set:\n",
      " [[643  23]\n",
      " [ 46   8]]\n",
      "\n",
      "Precision: 0.26\n",
      "Recall: 0.15\n",
      "F1 Score: 0.19\n",
      "ROC-AUC Score: 0.72\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Not Counterspeech       0.93      0.97      0.95       666\n",
      "    Counterspeech       0.26      0.15      0.19        54\n",
      "\n",
      "         accuracy                           0.90       720\n",
      "        macro avg       0.60      0.56      0.57       720\n",
      "     weighted avg       0.88      0.90      0.89       720\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1\n",
    "df = pd.read_csv(\"/Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: I added stratify=y in train_test_split to ensure that the class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set only\n",
    "oversampler = RandomOverSampler(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L1 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "# Step 6: Perform cross-validation on the oversampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the oversampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))\n",
    "\n",
    "# Step 11: Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line (random chance)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key notes:\n",
    "* The *stratified split* ensures that **both the training and test sets are representative of the original class distribution**, which is essential when dealing with imbalanced datasets. This makes sure that we’re not accidentally ending up with a highly imbalanced test set.\n",
    "* However, once the split is done, you apply **oversampling only on the training set to balance it**. The test set remains untouched, preserving the original imbalance for evaluating the model's performance on realistic data. That's why the stratified split helps maintain realism in evaluating model performance.\n",
    "\n",
    "Analysis of the output:\n",
    "1) The F1 score of 0.19 for Counterspeech indicates that while some counterspeech is being correctly identified, the model struggles to comprehensively capture the complex nature of counterspeech. This is likely due to its nuanced language, which can be sarcastic, indirect, or subtle, making it harder for the model to differentiate.\n",
    "2) The mean cross-validation accuracy of 0.98 indicates that the model performs very well on the training set and during cross-validation. However, this does not translate into similar performance on the test set, where the accuracy drops to 0.90. This discrepancy suggests **potential overfitting**: the model might be learning the specific patterns of the training set during oversampling, but it generalizes poorly to new, unseen data, especially when it comes to the minority class (Counterspeech). This is a common issue when using random oversampling, as the model may become too reliant on the duplicated data points.\n",
    "3) In any case, this combination of oversampling and stratify did not work out as expected...\n",
    "4) So I will try with other methods such as **SMOTE and SMOTE along with undersampling**.\n",
    "5) Finally, while TF-IDF with unigrams is effective, incorporating **bigrams/trigrams** or **word embeddings (like Word2Vec or Doc2Vec)** might allow the model to capture more nuanced relationships in counterspeech!\n",
    "6) I'll first try these changes noted above and then move to other *SML techniques* and different levels of *regularization*..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to test if there is overfitting?\n",
    "* Step 1: Split the Data.\n",
    "\n",
    "First, I need to split your dataset into training and test sets. Then, I will split the training set further into smaller training and validation subsets to analyze how the model behaves.\n",
    "\n",
    "* Step 2: Train the Model on Increasing Training Set Sizes\n",
    "\n",
    "I train the logistic regression model on increasing portions of the training set while keeping a validation set constant. This will allow me to generate learning curves that show the training and validation errors (or accuracy).\n",
    "\n",
    "* Step 3: Plot Learning Curves\n",
    "Plot the learning curves for both training and validation accuracy (or error) to visually inspect the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing if there is overfitting looking at bias-variance trade-off\n",
    "\n",
    "# Generate learning curves using increasing training set sizes\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    estimator=logreg_l1,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),  # Vary training set sizes from 10% to 100%\n",
    "    cv=10,  # 10-fold cross-validation\n",
    "    scoring='accuracy',  # Scoring metric (you can change this to 'f1', 'precision', etc.)\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation for training and validation scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "validation_mean = np.mean(validation_scores, axis=1)\n",
    "validation_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Training Score', color='blue')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)\n",
    "plt.plot(train_sizes, validation_mean, label='Validation Score', color='red')\n",
    "plt.fill_between(train_sizes, validation_mean - validation_std, validation_mean + validation_std, color='red', alpha=0.2)\n",
    "\n",
    "plt.title('Learning Curves (Logistic Regression)')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways:\n",
    "1) The consistently high training accuracy indicates that the model has low bias, as it can fit the training data almost perfectly. This means the model is sufficiently complex to capture the underlying patterns in the data during training.\n",
    "2) The gap between training accuracy and validation accuracy is evidence of high variance. The model generalizes less effectively on unseen data, which clearly suggests **overfitting**. The model has learned specific details and potentially noise from the training data, resulting in a perfect training performance but lower performance on new data (validation set).\n",
    "\n",
    "SUGGESTIONS OR WAYS TO GO:\n",
    "1) Apply more **regularization** to reduce overfitting and limit the model's ability to memorize the training data. For instance, in logistic regression, you could increase the value of the regularization parameter (C) to penalize large coefficients.\n",
    "2) Consider experimenting with models that have built-in regularization, such as **Random Forests or Gradient Boosting**, or using **cross-validation-based model tuning** to select the best model and hyperparameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 TF-IDF unigrams with random oversampling: **More Regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.93569132 0.97749196 0.93569132 0.92282958 0.95498392 0.95176849\n",
      " 0.93225806 0.95806452 0.92903226 0.94516129]\n",
      "Mean CV Accuracy: 0.9442972720672129\n",
      "Test Set Accuracy: 0.8930555555555556\n",
      "Confusion Matrix on Test Set:\n",
      " [[627  39]\n",
      " [ 38  16]]\n",
      "\n",
      "Precision: 0.29\n",
      "Recall: 0.30\n",
      "F1 Score: 0.29\n",
      "ROC-AUC Score: 0.72\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Not Counterspeech       0.94      0.94      0.94       666\n",
      "    Counterspeech       0.29      0.30      0.29        54\n",
      "\n",
      "         accuracy                           0.89       720\n",
      "        macro avg       0.62      0.62      0.62       720\n",
      "     weighted avg       0.89      0.89      0.89       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1\n",
    "df = pd.read_csv(\"/counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: I added stratify=y in train_test_split to ensure that the class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set only\n",
    "oversampler = RandomOverSampler(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L1 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.1, max_iter=1000) # note we increased regularization by decreasing C\n",
    "\n",
    "# Step 6: Perform cross-validation on the oversampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the oversampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways:\n",
    "1) Compared to the previous model with standard regularization, we have applied higher regularization. Precision for Counterspeech improved slightly from 0.26 (C = 1.0) to 0.29 (C = 0.1), while recall increased from 0.15 to 0.30, effectively doubling the recall. This is a key improvement, as the model is now identifying more Counterspeech instances. But still poor performance.\n",
    "2) The lower cross-validation accuracy and test accuracy indicate that the model is now less prone to overfitting. However, this comes at the cost of slightly lower test performance.\n",
    "\n",
    "Further steps:\n",
    "\n",
    "1) Since regularization reduces the model’s capacity to overfit, another approach to maintain or even improve accuracy is to focus on improving the quality of features through feature engineering (e.g. using **additional n-grams**, or more informative linguistic features, as we'll see afterwards when using trigrams!).\n",
    "2) We could continue experimenting with **different values of C** to see if there is any further improvement. Finding an optimal value for regularization could improve the model's performance.\n",
    "3) Alternatively, we could try with other regularization techniques (such as **L2 regularization or even elastic net**) to further improve the trade-off.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 Different values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Define a logistic regression model\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear')  # Using Lasso (L1) regularization\n",
    "\n",
    "# Set up the parameter grid to search for the best C value\n",
    "param_grid = {'C': np.logspace(-4, 4, 10)}  # Search over a wide range of C values (from 0.0001 to 10,000)\n",
    "\n",
    "# Set up the GridSearchCV to find the optimal C value\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=10, scoring='accuracy', n_jobs=-1)  # You can change 'scoring' to F1, precision, recall if needed\n",
    "\n",
    "# Fit the model to the training data and search for the best C value\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best C value and print it\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(f\"Best C value: {best_C}\")\n",
    "\n",
    "# Evaluate the model with the optimal C on the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test F1 Score: {f1}\")\n",
    "print(f\"Test Precision: {precision}\")\n",
    "print(f\"Test Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1\n",
    "df = pd.read_csv(\"counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: I added stratify=y in train_test_split to ensure that the class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set only\n",
    "oversampler = RandomOverSampler(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L1 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=0.01, max_iter=3000) # note we increased regularization by decreasing C\n",
    "\n",
    "# Step 6: Perform cross-validation on the oversampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the oversampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The cross-validation accuracy has dropped significantly, from around 0.94–0.98 in previous runs to a mean CV accuracy of 0.625. This sharp drop is a clear indication that the model is now underfitting, meaning it has become too simple due to the increased regularization.\n",
    "2) The F1 score for Counterspeech has increased slightly to 0.33, reflecting an overall improvement in how the model balances precision and recall. However, it is still low, indicating that the model is far from optimal for Counterspeech detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) TF-IDF with unigrams with **random oversampling**: Ridge Regression (L2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.97427653 0.99678457 0.9807074  0.98392283 0.97749196 0.99678457\n",
      " 0.98709677 0.98709677 0.99354839 0.98387097]\n",
      "Mean CV Accuracy: 0.9861580748884972\n",
      "Test Set Accuracy: 0.9138888888888889\n",
      "Confusion Matrix on Test Set:\n",
      " [[650  16]\n",
      " [ 46   8]]\n",
      "\n",
      "Precision: 0.33\n",
      "Recall: 0.15\n",
      "F1 Score: 0.21\n",
      "ROC-AUC Score: 0.69\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Not Counterspeech       0.93      0.98      0.95       666\n",
      "    Counterspeech       0.33      0.15      0.21        54\n",
      "\n",
      "         accuracy                           0.91       720\n",
      "        macro avg       0.63      0.56      0.58       720\n",
      "     weighted avg       0.89      0.91      0.90       720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1\n",
    "df = pd.read_csv(\"counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: I added stratify=y in train_test_split to ensure that the class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set only\n",
    "oversampler = RandomOverSampler(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L1 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l2', solver='liblinear', C=1.0, max_iter=1000) # note we increased regularization by decreasing C\n",
    "\n",
    "# Step 6: Perform cross-validation on the oversampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the oversampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) With Ridge regularization, the coefficients are penalized more evenly, meaning that large coefficients are reduced, but the model doesn't force many coefficients to exactly zero, as Lasso does.\n",
    "2) Ridge regression generally results in better stability and generalization when there is no clear indication that sparsity (many coefficients being zero) is crucial. In this case, it seems that this is helping the model balance flexibility and generalization more evenly than Lasso.\n",
    "3) However, the improvement is minimal, so let's try with higher regularization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1\n",
    "df = pd.read_csv(\"counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: I added stratify=y in train_test_split to ensure that the class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set only\n",
    "oversampler = RandomOverSampler(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L1 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l2', solver='liblinear', C=0.1, max_iter=1000) # note we increased regularization by decreasing C\n",
    "\n",
    "# Step 6: Perform cross-validation on the oversampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the oversampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1\n",
    "df = pd.read_csv(\"counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: I added stratify=y in train_test_split to ensure that the class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set only\n",
    "oversampler = RandomOverSampler(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L1 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l2', solver='liblinear', C=0.01, max_iter=1000) # note we increased regularization by decreasing C\n",
    "\n",
    "# Step 6: Perform cross-validation on the oversampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the oversampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there is clear risk of overfitting. It performs poorly when faced with new, unseen data... Let's try with SMOTE instead of random oversampling to test if there are some improvements, because both Lasso and Ridge perform poor in classifying counterspeech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) TF-IDF with unigrams with **SMOTE** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Step 1\n",
    "df = pd.read_csv(\"counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: I added stratify=y in train_test_split to ensure that the class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set only\n",
    "smote = SMOTE(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L1 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000) # note we increased regularization by decreasing C\n",
    "\n",
    "# Step 6: Perform cross-validation on the oversampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the oversampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Step 1\n",
    "df = pd.read_csv(\"counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: I added stratify=y in train_test_split to ensure that the class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply SMOTE to the training set only\n",
    "smote = SMOTE(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L2 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l2', solver='liblinear', C=1.0, max_iter=1000) # note we increased regularization by decreasing C\n",
    "\n",
    "# Step 6: Perform cross-validation on the oversampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the oversampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"counterspeech/DFM_tfidf.csv\", sep = \",\")\n",
    "\n",
    "# Step 2: Define features (X) and label (y)\n",
    "X = df.drop(columns=[\"Unnamed: 0\",'counter']) \n",
    "y = df['counter']\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets (70/30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1998, stratify=y)\n",
    "\n",
    "#### NB: Stratify=y in train_test_split ensures class distribution is maintained in both the training and test sets\n",
    "\n",
    "# Step 4: Apply SMOTE combined with undersampling (SMOTETomek) to the training set only\n",
    "smote_tomek = SMOTETomek(random_state=1998)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Define and perform logistic regression with L1 regularization\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000) # L1 regularization (Lasso)\n",
    "\n",
    "# Step 6: Perform cross-validation on the resampled training set\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Step 7: Train the logistic regression model on the resampled training set\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 8: Make predictions on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 9: Model performance evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "\n",
    "# Step 10: Calculate Precision, Recall, F1-Score, and ROC-AUC\n",
    "y_pred_proba = logreg_l1.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class (Counterspeech)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC Score: {roc_auc:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs poorly again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) TF-IDF with trigrams with **random oversampling**: Lasso & Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>schwule_rechte_strasse</th>\n",
       "      <th>rechte_strasse_gehen</th>\n",
       "      <th>strasse_gehen_schoen</th>\n",
       "      <th>gehen_schoen_sehen</th>\n",
       "      <th>schoen_sehen_freiheitsgedanke</th>\n",
       "      <th>sehen_freiheitsgedanke_international</th>\n",
       "      <th>freiheitsgedanke_international_fruechte</th>\n",
       "      <th>international_fruechte_traegt</th>\n",
       "      <th>nehme_christopher_street</th>\n",
       "      <th>...</th>\n",
       "      <th>gewalt_user_dies</th>\n",
       "      <th>user_dies_deren</th>\n",
       "      <th>dies_deren_einziges</th>\n",
       "      <th>deren_einziges_kommen</th>\n",
       "      <th>einziges_kommen_doch</th>\n",
       "      <th>kommen_doch_hir</th>\n",
       "      <th>doch_hir_garkein</th>\n",
       "      <th>hir_garkein_zaun</th>\n",
       "      <th>garkein_zaun_oder</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>2.902909</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2395</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2396</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2397</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2399</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 22763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  schwule_rechte_strasse  rechte_strasse_gehen  \\\n",
       "0              1                 3.38003              2.902909   \n",
       "1              2                 0.00000              0.000000   \n",
       "2              3                 0.00000              0.000000   \n",
       "3              4                 0.00000              0.000000   \n",
       "4              5                 0.00000              0.000000   \n",
       "...          ...                     ...                   ...   \n",
       "2394        2395                 0.00000              0.000000   \n",
       "2395        2396                 0.00000              0.000000   \n",
       "2396        2397                 0.00000              0.000000   \n",
       "2397        2398                 0.00000              0.000000   \n",
       "2398        2399                 0.00000              0.000000   \n",
       "\n",
       "      strasse_gehen_schoen  gehen_schoen_sehen  schoen_sehen_freiheitsgedanke  \\\n",
       "0                  3.38003             3.38003                        3.38003   \n",
       "1                  0.00000             0.00000                        0.00000   \n",
       "2                  0.00000             0.00000                        0.00000   \n",
       "3                  0.00000             0.00000                        0.00000   \n",
       "4                  0.00000             0.00000                        0.00000   \n",
       "...                    ...                 ...                            ...   \n",
       "2394               0.00000             0.00000                        0.00000   \n",
       "2395               0.00000             0.00000                        0.00000   \n",
       "2396               0.00000             0.00000                        0.00000   \n",
       "2397               0.00000             0.00000                        0.00000   \n",
       "2398               0.00000             0.00000                        0.00000   \n",
       "\n",
       "      sehen_freiheitsgedanke_international  \\\n",
       "0                                  3.38003   \n",
       "1                                  0.00000   \n",
       "2                                  0.00000   \n",
       "3                                  0.00000   \n",
       "4                                  0.00000   \n",
       "...                                    ...   \n",
       "2394                               0.00000   \n",
       "2395                               0.00000   \n",
       "2396                               0.00000   \n",
       "2397                               0.00000   \n",
       "2398                               0.00000   \n",
       "\n",
       "      freiheitsgedanke_international_fruechte  international_fruechte_traegt  \\\n",
       "0                                     3.38003                        3.38003   \n",
       "1                                     0.00000                        0.00000   \n",
       "2                                     0.00000                        0.00000   \n",
       "3                                     0.00000                        0.00000   \n",
       "4                                     0.00000                        0.00000   \n",
       "...                                       ...                            ...   \n",
       "2394                                  0.00000                        0.00000   \n",
       "2395                                  0.00000                        0.00000   \n",
       "2396                                  0.00000                        0.00000   \n",
       "2397                                  0.00000                        0.00000   \n",
       "2398                                  0.00000                        0.00000   \n",
       "\n",
       "      nehme_christopher_street  ...  gewalt_user_dies  user_dies_deren  \\\n",
       "0                      0.00000  ...           0.00000          0.00000   \n",
       "1                      3.38003  ...           0.00000          0.00000   \n",
       "2                      0.00000  ...           0.00000          0.00000   \n",
       "3                      0.00000  ...           0.00000          0.00000   \n",
       "4                      0.00000  ...           0.00000          0.00000   \n",
       "...                        ...  ...               ...              ...   \n",
       "2394                   0.00000  ...           0.00000          0.00000   \n",
       "2395                   0.00000  ...           0.00000          0.00000   \n",
       "2396                   0.00000  ...           0.00000          0.00000   \n",
       "2397                   0.00000  ...           0.00000          0.00000   \n",
       "2398                   0.00000  ...           3.38003          3.38003   \n",
       "\n",
       "      dies_deren_einziges  deren_einziges_kommen  einziges_kommen_doch  \\\n",
       "0                 0.00000                0.00000               0.00000   \n",
       "1                 0.00000                0.00000               0.00000   \n",
       "2                 0.00000                0.00000               0.00000   \n",
       "3                 0.00000                0.00000               0.00000   \n",
       "4                 0.00000                0.00000               0.00000   \n",
       "...                   ...                    ...                   ...   \n",
       "2394              0.00000                0.00000               0.00000   \n",
       "2395              0.00000                0.00000               0.00000   \n",
       "2396              0.00000                0.00000               0.00000   \n",
       "2397              0.00000                0.00000               0.00000   \n",
       "2398              3.38003                3.38003               3.38003   \n",
       "\n",
       "      kommen_doch_hir  doch_hir_garkein  hir_garkein_zaun  garkein_zaun_oder  \\\n",
       "0             0.00000           0.00000           0.00000            0.00000   \n",
       "1             0.00000           0.00000           0.00000            0.00000   \n",
       "2             0.00000           0.00000           0.00000            0.00000   \n",
       "3             0.00000           0.00000           0.00000            0.00000   \n",
       "4             0.00000           0.00000           0.00000            0.00000   \n",
       "...               ...               ...               ...                ...   \n",
       "2394          0.00000           0.00000           0.00000            0.00000   \n",
       "2395          0.00000           0.00000           0.00000            0.00000   \n",
       "2396          0.00000           0.00000           0.00000            0.00000   \n",
       "2397          0.00000           0.00000           0.00000            0.00000   \n",
       "2398          3.38003           3.38003           3.38003            3.38003   \n",
       "\n",
       "      counter  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "2394        0  \n",
       "2395        1  \n",
       "2396        0  \n",
       "2397        0  \n",
       "2398        0  \n",
       "\n",
       "[2399 rows x 22763 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.read_csv(\"counterspeech/DFM_tfidf_trigrams.csv\", sep = \",\")\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "X = df_tfidf.drop(columns=[\"Unnamed: 0\",'counter'])  # the features are X\n",
    "y = df_tfidf['counter']  # Target variable (counter label)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 92382838, stratify=y)\n",
    "\n",
    "# Step 3: Apply random oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=92382838)\n",
    "X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 4: Train a logistic regression model with L1 regularization (Lasso)\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)\n",
    "logreg_l1.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# Step 5: Evaluate the model on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 6: Model performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Step 7: Cross-validation with SMOTE and TF-IDF features\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_oversampled, y_train_oversampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Print results\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {cv_scores.mean()}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really poor performance again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) TF-IDF with trigrams with **SMOTE** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>schwule_rechte_strasse</th>\n",
       "      <th>rechte_strasse_gehen</th>\n",
       "      <th>strasse_gehen_schoen</th>\n",
       "      <th>gehen_schoen_sehen</th>\n",
       "      <th>schoen_sehen_freiheitsgedanke</th>\n",
       "      <th>sehen_freiheitsgedanke_international</th>\n",
       "      <th>freiheitsgedanke_international_fruechte</th>\n",
       "      <th>international_fruechte_traegt</th>\n",
       "      <th>nehme_christopher_street</th>\n",
       "      <th>...</th>\n",
       "      <th>gewalt_user_dies</th>\n",
       "      <th>user_dies_deren</th>\n",
       "      <th>dies_deren_einziges</th>\n",
       "      <th>deren_einziges_kommen</th>\n",
       "      <th>einziges_kommen_doch</th>\n",
       "      <th>kommen_doch_hir</th>\n",
       "      <th>doch_hir_garkein</th>\n",
       "      <th>hir_garkein_zaun</th>\n",
       "      <th>garkein_zaun_oder</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>2.902909</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2395</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2396</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2397</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2399</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>3.38003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 22763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  schwule_rechte_strasse  rechte_strasse_gehen  \\\n",
       "0              1                 3.38003              2.902909   \n",
       "1              2                 0.00000              0.000000   \n",
       "2              3                 0.00000              0.000000   \n",
       "3              4                 0.00000              0.000000   \n",
       "4              5                 0.00000              0.000000   \n",
       "...          ...                     ...                   ...   \n",
       "2394        2395                 0.00000              0.000000   \n",
       "2395        2396                 0.00000              0.000000   \n",
       "2396        2397                 0.00000              0.000000   \n",
       "2397        2398                 0.00000              0.000000   \n",
       "2398        2399                 0.00000              0.000000   \n",
       "\n",
       "      strasse_gehen_schoen  gehen_schoen_sehen  schoen_sehen_freiheitsgedanke  \\\n",
       "0                  3.38003             3.38003                        3.38003   \n",
       "1                  0.00000             0.00000                        0.00000   \n",
       "2                  0.00000             0.00000                        0.00000   \n",
       "3                  0.00000             0.00000                        0.00000   \n",
       "4                  0.00000             0.00000                        0.00000   \n",
       "...                    ...                 ...                            ...   \n",
       "2394               0.00000             0.00000                        0.00000   \n",
       "2395               0.00000             0.00000                        0.00000   \n",
       "2396               0.00000             0.00000                        0.00000   \n",
       "2397               0.00000             0.00000                        0.00000   \n",
       "2398               0.00000             0.00000                        0.00000   \n",
       "\n",
       "      sehen_freiheitsgedanke_international  \\\n",
       "0                                  3.38003   \n",
       "1                                  0.00000   \n",
       "2                                  0.00000   \n",
       "3                                  0.00000   \n",
       "4                                  0.00000   \n",
       "...                                    ...   \n",
       "2394                               0.00000   \n",
       "2395                               0.00000   \n",
       "2396                               0.00000   \n",
       "2397                               0.00000   \n",
       "2398                               0.00000   \n",
       "\n",
       "      freiheitsgedanke_international_fruechte  international_fruechte_traegt  \\\n",
       "0                                     3.38003                        3.38003   \n",
       "1                                     0.00000                        0.00000   \n",
       "2                                     0.00000                        0.00000   \n",
       "3                                     0.00000                        0.00000   \n",
       "4                                     0.00000                        0.00000   \n",
       "...                                       ...                            ...   \n",
       "2394                                  0.00000                        0.00000   \n",
       "2395                                  0.00000                        0.00000   \n",
       "2396                                  0.00000                        0.00000   \n",
       "2397                                  0.00000                        0.00000   \n",
       "2398                                  0.00000                        0.00000   \n",
       "\n",
       "      nehme_christopher_street  ...  gewalt_user_dies  user_dies_deren  \\\n",
       "0                      0.00000  ...           0.00000          0.00000   \n",
       "1                      3.38003  ...           0.00000          0.00000   \n",
       "2                      0.00000  ...           0.00000          0.00000   \n",
       "3                      0.00000  ...           0.00000          0.00000   \n",
       "4                      0.00000  ...           0.00000          0.00000   \n",
       "...                        ...  ...               ...              ...   \n",
       "2394                   0.00000  ...           0.00000          0.00000   \n",
       "2395                   0.00000  ...           0.00000          0.00000   \n",
       "2396                   0.00000  ...           0.00000          0.00000   \n",
       "2397                   0.00000  ...           0.00000          0.00000   \n",
       "2398                   0.00000  ...           3.38003          3.38003   \n",
       "\n",
       "      dies_deren_einziges  deren_einziges_kommen  einziges_kommen_doch  \\\n",
       "0                 0.00000                0.00000               0.00000   \n",
       "1                 0.00000                0.00000               0.00000   \n",
       "2                 0.00000                0.00000               0.00000   \n",
       "3                 0.00000                0.00000               0.00000   \n",
       "4                 0.00000                0.00000               0.00000   \n",
       "...                   ...                    ...                   ...   \n",
       "2394              0.00000                0.00000               0.00000   \n",
       "2395              0.00000                0.00000               0.00000   \n",
       "2396              0.00000                0.00000               0.00000   \n",
       "2397              0.00000                0.00000               0.00000   \n",
       "2398              3.38003                3.38003               3.38003   \n",
       "\n",
       "      kommen_doch_hir  doch_hir_garkein  hir_garkein_zaun  garkein_zaun_oder  \\\n",
       "0             0.00000           0.00000           0.00000            0.00000   \n",
       "1             0.00000           0.00000           0.00000            0.00000   \n",
       "2             0.00000           0.00000           0.00000            0.00000   \n",
       "3             0.00000           0.00000           0.00000            0.00000   \n",
       "4             0.00000           0.00000           0.00000            0.00000   \n",
       "...               ...               ...               ...                ...   \n",
       "2394          0.00000           0.00000           0.00000            0.00000   \n",
       "2395          0.00000           0.00000           0.00000            0.00000   \n",
       "2396          0.00000           0.00000           0.00000            0.00000   \n",
       "2397          0.00000           0.00000           0.00000            0.00000   \n",
       "2398          3.38003           3.38003           3.38003            3.38003   \n",
       "\n",
       "      counter  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "2394        0  \n",
       "2395        1  \n",
       "2396        0  \n",
       "2397        0  \n",
       "2398        0  \n",
       "\n",
       "[2399 rows x 22763 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "df_tfidf = pd.read_csv(\"counterspeech/DFM_tfidf_trigrams.csv\", sep = \",\")\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tfidf.drop(columns=[\"Unnamed: 0\",'counter'])  # the features are X\n",
    "y = df_tfidf['counter']  # Target variable (counter label)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training set to handle class imbalance by generating synthetic samples for the minority class.\n",
    "smote = SMOTE(random_state=9999)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 4: Train a logistic regression model with L1 regularization (Lasso)\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=200)  # C can be tuned\n",
    "logreg_l1.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Step 5: Evaluate the model on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 6: Model performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Step 7: Cross-validation with SMOTE and TF-IDF features\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_smote, y_train_smote, cv=10, scoring='accuracy')\n",
    "\n",
    "# Print results\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {cv_scores.mean()}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Again, it does not classify counterspeech instances correctly.\n",
    "\n",
    "* NB: To apply undersampling combined with SMOTE in Python, we can use a technique called SMOTEENN (SMOTE + Edited Nearest Neighbors) or SMOTETomek (SMOTE + Tomek Links), which first applies SMOTE to handle the minority class and then undersamples the majority class to remove noisy examples. \n",
    "\n",
    "2) Let's try both SMOTE on the minority class and undersampling for the majority class..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) TF-IDF with trigrams with **SMOTE and undersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "\n",
    "# Step 3: Apply SMOTE + Undersampling (SMOTETomek) to the training set\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 4: Train a logistic regression model with L1 regularization (Lasso)\n",
    "logreg_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0)  # C can be tuned\n",
    "logreg_l1.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 5: Evaluate the model on the test set\n",
    "y_pred = logreg_l1.predict(X_test)\n",
    "\n",
    "# Step 6: Model performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Step 7: Cross-validation with SMOTE + undersampling (SMOTETomek) and TF-IDF trigram features\n",
    "cv_scores = cross_val_score(logreg_l1, X_train_resampled, y_train_resampled, cv=10, scoring='accuracy')\n",
    "\n",
    "# Print results\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {cv_scores.mean()}')\n",
    "print(f'Test Set Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix on Test Set:\\n {conf_matrix}')\n",
    "print(f'\\nPrecision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print a full classification report for both classes\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Document embeddings (Doc2Vec + BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key notes regarding the use of word and document embeddings:\n",
    "1) Tweets or short comments typically consist of few words, making document embeddings a natural fit because they capture the entire context of the comment in a single vector. Using word embeddings could still be useful, but since each comment contains so few words, their effectiveness might be limited compared to document embeddings that summarize the entire tweet.\n",
    "2) If we are interested in understanding the individual importance of words (e.g. the importance of a word like \"hate\" or \"support\" in counterspeech), word embeddings could be informative. However, tweets/comments often contain specific phrases or multiple words that work together to convey meaning, and so document embeddings might capture more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>counter</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>language</th>\n",
       "      <th>comment_lemmatized</th>\n",
       "      <th>comment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Schwule, die für ihre Rechte auf die Straße ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>schwule rechte strasse gehen schoen sehen frei...</td>\n",
       "      <td>german</td>\n",
       "      <td>schwul rechte strassen gehen scho sehen freihe...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ich nehme an das ist der Christopher Street Da...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nehme christopher street day oae asiatischen l...</td>\n",
       "      <td>german</td>\n",
       "      <td>nehmen christopher streen day oa asiatischen l...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Solange Homosexuelle nicht in allen Ländern si...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>solange homosexuelle nicht allen laendern sich...</td>\n",
       "      <td>german</td>\n",
       "      <td>solange homosexuell nicht alle laendern sicher...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Homosexualität wird in unserer Gesellschaft of...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>homosexualitaet gesellschaft oftmals gegeissel...</td>\n",
       "      <td>german</td>\n",
       "      <td>homosexualitaen sellschafen oftmals gegeisselt...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Echt schade, dass dafür extra eine Parade stat...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>echt schade dafuer extra parade finden und nic...</td>\n",
       "      <td>german</td>\n",
       "      <td>echt schade dafuer extra parade finden und nic...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2395</td>\n",
       "      <td>Ich bitte euch darum dieses Bild genau anzuseh...</td>\n",
       "      <td>0</td>\n",
       "      <td>2421</td>\n",
       "      <td>bitte euch bild genau anzusehen menschen schle...</td>\n",
       "      <td>german</td>\n",
       "      <td>bitten ihr bild genau ansehen mensch schlecht ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2396</td>\n",
       "      <td>Wie kannst du nur so etwas behaupten, Wintergr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2422</td>\n",
       "      <td>du behaupten wintergruen meisten unendliches l...</td>\n",
       "      <td>german</td>\n",
       "      <td>du behaupten wintergruen meist unendlich leid ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2397</td>\n",
       "      <td>Gartenzaunvorstand, zu bist so einseitig. Sie ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2423</td>\n",
       "      <td>gartenzaunvorstand einseitig laufen neuen hoff...</td>\n",
       "      <td>german</td>\n",
       "      <td>gartenzaunvorstehen einseitig laufen neu hoffe...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>Ich kann usercfor nicht zustimmen. Ich sehe ke...</td>\n",
       "      <td>0</td>\n",
       "      <td>2424</td>\n",
       "      <td>usercfor nicht zustimmen sehe keine wuetenden ...</td>\n",
       "      <td>german</td>\n",
       "      <td>usercfor nicht zustimmen sehe kein wuetend flu...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2399</td>\n",
       "      <td>man sieht auf dem Foto echt nicht viel, auserd...</td>\n",
       "      <td>0</td>\n",
       "      <td>2425</td>\n",
       "      <td>man sieht foto echt nicht viel auserdem allerw...</td>\n",
       "      <td>german</td>\n",
       "      <td>man sehen foto echt nicht viel auserdem allerw...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  counter  \\\n",
       "0              1  Schwule, die für ihre Rechte auf die Straße ge...        0   \n",
       "1              2  Ich nehme an das ist der Christopher Street Da...        0   \n",
       "2              3  Solange Homosexuelle nicht in allen Ländern si...        0   \n",
       "3              4  Homosexualität wird in unserer Gesellschaft of...        0   \n",
       "4              5  Echt schade, dass dafür extra eine Parade stat...        0   \n",
       "...          ...                                                ...      ...   \n",
       "2394        2395  Ich bitte euch darum dieses Bild genau anzuseh...        0   \n",
       "2395        2396  Wie kannst du nur so etwas behaupten, Wintergr...        1   \n",
       "2396        2397  Gartenzaunvorstand, zu bist so einseitig. Sie ...        0   \n",
       "2397        2398  Ich kann usercfor nicht zustimmen. Ich sehe ke...        0   \n",
       "2398        2399  man sieht auf dem Foto echt nicht viel, auserd...        0   \n",
       "\n",
       "        id                                    comment_cleaned language  \\\n",
       "0        1  schwule rechte strasse gehen schoen sehen frei...   german   \n",
       "1        2  nehme christopher street day oae asiatischen l...   german   \n",
       "2        3  solange homosexuelle nicht allen laendern sich...   german   \n",
       "3        4  homosexualitaet gesellschaft oftmals gegeissel...   german   \n",
       "4        5  echt schade dafuer extra parade finden und nic...   german   \n",
       "...    ...                                                ...      ...   \n",
       "2394  2421  bitte euch bild genau anzusehen menschen schle...   german   \n",
       "2395  2422  du behaupten wintergruen meisten unendliches l...   german   \n",
       "2396  2423  gartenzaunvorstand einseitig laufen neuen hoff...   german   \n",
       "2397  2424  usercfor nicht zustimmen sehe keine wuetenden ...   german   \n",
       "2398  2425  man sieht foto echt nicht viel auserdem allerw...   german   \n",
       "\n",
       "                                     comment_lemmatized  comment_length  \n",
       "0     schwul rechte strassen gehen scho sehen freihe...              10  \n",
       "1     nehmen christopher streen day oa asiatischen l...              19  \n",
       "2     solange homosexuell nicht alle laendern sicher...              18  \n",
       "3     homosexualitaen sellschafen oftmals gegeisselt...               7  \n",
       "4     echt schade dafuer extra parade finden und nic...              10  \n",
       "...                                                 ...             ...  \n",
       "2394  bitten ihr bild genau ansehen mensch schlecht ...              33  \n",
       "2395  du behaupten wintergruen meist unendlich leid ...              11  \n",
       "2396  gartenzaunvorstehen einseitig laufen neu hoffe...               7  \n",
       "2397  usercfor nicht zustimmen sehe kein wuetend flu...              40  \n",
       "2398  man sehen foto echt nicht viel auserdem allerw...              20  \n",
       "\n",
       "[2399 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = pd.read_csv(\"counterspeech/df_cleaned.csv\", sep = \",\")\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>schwule rechte strasse gehen schoen sehen frei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nehme christopher street day oae asiatischen l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>solange homosexuelle nicht allen laendern sich...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homosexualitaet gesellschaft oftmals gegeissel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>echt schade dafuer extra parade finden und nic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>bitte euch bild genau anzusehen menschen schle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>du behaupten wintergruen meisten unendliches l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>gartenzaunvorstand einseitig laufen neuen hoff...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>usercfor nicht zustimmen sehe keine wuetenden ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>man sieht foto echt nicht viel auserdem allerw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_cleaned  counter\n",
       "0     schwule rechte strasse gehen schoen sehen frei...        0\n",
       "1     nehme christopher street day oae asiatischen l...        0\n",
       "2     solange homosexuelle nicht allen laendern sich...        0\n",
       "3     homosexualitaet gesellschaft oftmals gegeissel...        0\n",
       "4     echt schade dafuer extra parade finden und nic...        0\n",
       "...                                                 ...      ...\n",
       "2394  bitte euch bild genau anzusehen menschen schle...        0\n",
       "2395  du behaupten wintergruen meisten unendliches l...        1\n",
       "2396  gartenzaunvorstand einseitig laufen neuen hoff...        0\n",
       "2397  usercfor nicht zustimmen sehe keine wuetenden ...        0\n",
       "2398  man sieht foto echt nicht viel auserdem allerw...        0\n",
       "\n",
       "[2399 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Keep only the relevant columns (comment_cleaned and counter)\n",
    "df_cleaned_filtered = df_cleaned[['comment_cleaned', 'counter']]\n",
    "df_cleaned_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/s91hbd9d4gq_flqnt0s42m300000gn/T/ipykernel_4801/2863152071.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned_filtered['doc2vec_embeddings'] = df_cleaned_filtered['comment_cleaned'].apply(lambda x: model_d2v.infer_vector(x.split()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     comment_cleaned  counter  \\\n",
      "0  schwule rechte strasse gehen schoen sehen frei...        0   \n",
      "1  nehme christopher street day oae asiatischen l...        0   \n",
      "2  solange homosexuelle nicht allen laendern sich...        0   \n",
      "3  homosexualitaet gesellschaft oftmals gegeissel...        0   \n",
      "4  echt schade dafuer extra parade finden und nic...        0   \n",
      "\n",
      "                                  doc2vec_embeddings  \n",
      "0  [-0.004673641, 0.0005091863, -0.0041475664, -0...  \n",
      "1  [-0.01988966, 0.042408857, 0.027161792, -0.019...  \n",
      "2  [-0.00712244, 0.008098293, 0.0067138784, 6.438...  \n",
      "3  [-0.0005600981, -0.006271284, -0.0067579416, 0...  \n",
      "4  [-0.0074888435, 0.01806344, 0.011724604, -0.01...  \n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Step 2: Tokenize the comment_cleaned column and prepare TaggedDocument objects for Doc2Vec\n",
    "tagged_docs = [TaggedDocument(words=row.split(), tags=[str(i)]) for i, row in enumerate(df_cleaned_filtered['comment_cleaned'])]\n",
    "\n",
    "# Step 3: Train the Doc2Vec model\n",
    "model_d2v = Doc2Vec(tagged_docs, vector_size=100, window=8, min_count=2, workers=4, epochs=10)\n",
    "# The window size defines the maximum distance between the current word and the surrounding words that the model considers when building word embeddings.\n",
    "# The min_count parameter specifies the minimum frequency of words that will be considered in the model. Words that appear less than min_count times in the corpus are ignored.\n",
    "# The workers parameter specifies the number of CPU cores to use when training the model.\n",
    "\n",
    "# Step 4: Save the trained Doc2Vec model (optional, for later use)\n",
    "model_d2v.save(\"doc2vec_model.model\")\n",
    "\n",
    "# Step 5: Generate Doc2Vec embeddings for each document in the dataset\n",
    "# The `infer_vector` function generates a vector representation of the document\n",
    "df_cleaned_filtered['doc2vec_embeddings'] = df_cleaned_filtered['comment_cleaned'].apply(lambda x: model_d2v.infer_vector(x.split()))\n",
    "\n",
    "# Step 6: Save the resulting dataframe with embeddings to a CSV file\n",
    "df_cleaned_filtered.to_csv('doc2vec_embeddings.csv', index=False)\n",
    "\n",
    "# Optionally, check the first few rows to see the embeddings\n",
    "print(df_cleaned_filtered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes:\n",
    "1) Regarding the embeddings column: The doc2vec_embeddings column contains numeric vectors for each comment in the comment_cleaned column. These vectors represent the document embeddings generated by the Doc2Vec model. Each vector is a dense representation of the entire comment, capturing its semantic meaning in a multi-dimensional space (based on the vector size I specified).\n",
    "2) In NLP, the choice of vector size typically depends on the nature of the data. For short texts like these comments/tweets (which average 15-20 words, as we saw in R when preparing the data), a vector size between 50 and 300 is commonly used in social media studies to balance the semantic richness of the embeddings and computational efficiency.\n",
    "3) A vector size of 100 is often chosen as a starting point because it often works well in tasks like sentiment analysis, topic modeling, and classification of short content.\n",
    "4) From practical experience and from other NLP studies, training Doc2Vec models for around 5 to 20 epochs often yields good results. Starting with 10 epochs is common because it is neither too short (where the model might miss important relationships) nor too long (where overfitting could occur).\n",
    "5) Using 4 CPU cores (`workers = 4`) allows for faster training by parallelizing the workload, making the training process more efficient for handling a dataset of short texts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Load the dataset with doc2vec embeddings\n",
    "df = pd.read_csv('counterspeech/doc2vec_embeddings.csv', sep=\",\")\n",
    "\n",
    "# Define a function to safely parse the embedding strings\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (Doc2Vec embeddings) and target (counter)\n",
    "# Apply the function to convert the embeddings to lists of floats\n",
    "X = df['doc2vec_embeddings'].apply(parse_embedding_string).tolist()\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=521998, stratify=y)\n",
    "\n",
    "# Step 4: Initialize and train a logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight='balanced') # Increased max_iter to ensure convergence + weights\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)  # Assuming 1 is the label for counterspeech\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really good classifier... Let's try with word and document embeddings using OpenAI's API to access their word embedding models.\n",
    "\n",
    "However, before that, let's try combining document embeddings and SMOTE or random oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Load the dataset with doc2vec embeddings\n",
    "df = pd.read_csv('/Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/doc2vec_embeddings.csv', sep=\",\")\n",
    "\n",
    "# Define a function to safely parse the embedding strings\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (Doc2Vec embeddings) and target (counter)\n",
    "# Apply the function to convert the embeddings to lists of floats\n",
    "X = df['doc2vec_embeddings'].apply(parse_embedding_string).tolist()\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=521998, stratify=y)\n",
    "\n",
    "# Step 4: Initialize and train a logistic regression model\n",
    "logreg = LogisticRegression(penalty=\"l1\",solver=\"liblinear\", max_iter=1000, class_weight='balanced') # Increased max_iter to ensure convergence + weights\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Document embeddings (DOC2VEC) with SMOTE + STRATIFY + CLASS WEIGHTS   ##############\n",
    "\n",
    "# Step 1: Load the dataset with doc2vec embeddings\n",
    "df = pd.read_csv('/Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/doc2vec_embeddings.csv', sep=\",\")\n",
    "\n",
    "# Define a function to safely parse the embedding strings\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (Doc2Vec embeddings) and target (counter)\n",
    "X = df['doc2vec_embeddings'].apply(parse_embedding_string).tolist()\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test), stratifying by class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=521998, stratify=y)\n",
    "\n",
    "# Step 4: Apply SMOTE to the training data (balancing the classes)\n",
    "smote = SMOTE(random_state=521998)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Initialize and train a logistic regression model with L1 regularization (no class_weight since SMOTE is used)\n",
    "logreg = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=1000) \n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 6: Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential issue is that most word/document embedding models are trained in English corpora! So let's try with German-based models instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***WATCH OUT WHEN REPLICATING - GENERATING DOCUMENT EMBEDDINGS WITH BERT MODEL TOOK ME OVER 5 MINUTES AND 200% OF CPU USAGE - ALMOST BURNED!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# pip install transformers\n",
    "df_cleaned = pd.read_csv(\"counterspeech/df_cleaned.csv\", sep = \",\")\n",
    "df_cleaned_filtered = df_cleaned[['comment_cleaned', 'counter']]\n",
    "\n",
    "\n",
    "# Step 2: Load the pre-trained BERT model and tokenizer (German-specific model)\n",
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-german-cased')\n",
    "model = BertModel.from_pretrained('dbmdz/bert-base-german-cased')\n",
    "\n",
    "# Step 3: Generate BERT embeddings for each comment\n",
    "#def generate_bert_embeddings(text):\n",
    "    # Tokenize the text and add the special tokens (CLS and SEP)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # Forward pass through the BERT model\n",
    "    with torch.no_grad():  # Turn off gradient tracking (inference only)\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Take the output of [CLS] token (first token of the sequence)\n",
    "    # The CLS token is often used for sentence-level classification tasks\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    \n",
    "    return cls_embedding\n",
    "\n",
    "# Step 4: Apply the function to the 'comment_cleaned' column to generate embeddings\n",
    "df_cleaned_filtered['bert_embeddings'] = df_cleaned_filtered['comment_cleaned'].apply(lambda x: generate_bert_embeddings(x))\n",
    "\n",
    "# Step 5: Save the resulting dataframe with embeddings to a CSV file\n",
    "df_cleaned_filtered.to_csv('bert_embeddings.csv', index=False)\n",
    "\n",
    "# Optionally, check the first few rows to see the embeddings\n",
    "print(df_cleaned_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Document embeddings (BERT in German) with SMOTE + STRATIFY + CLASS WEIGHTS   ##############\n",
    "\n",
    "# Step 1: Load the dataset with Bert embeddings\n",
    "df = pd.read_csv('counterspeech/bert_embeddings.csv', sep=\",\")\n",
    "\n",
    "# Define a function to safely parse the embedding strings\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (BERT embeddings) and target (counter)\n",
    "X = df['bert_embeddings'].apply(parse_embedding_string).tolist()\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test), stratifying by class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=521998, stratify=y)\n",
    "\n",
    "# Step 4: Apply SMOTE to the training data (balancing the classes)\n",
    "smote = SMOTE(random_state=521998)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Initialize and train a logistic regression model with L1 regularization (no class_weight since SMOTE is used)\n",
    "logreg = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=1000, C=0.1) \n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 6: Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a noticeable improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) TF-IDF with unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) TF-IDF with trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load dataset with document embeddings\n",
    "df = pd.read_csv('counterspeech/doc2vec_embeddings.csv', sep=\",\") # not in German\n",
    "# df = pd.read_csv('counterspeech/bert_embeddings.csv', sep=\",\") # when using BERT embeddings in German!\n",
    "\n",
    "# Define a function to safely parse the embedding strings into lists of floats\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (Doc2Vec embeddings) and target (counter)\n",
    "X = df['doc2vec_embeddings'].apply(parse_embedding_string).tolist()  # Document embeddings\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test), stratifying by class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=521998, stratify=y)\n",
    "\n",
    "# Step 4: Standardize the embeddings (optional for Decision Trees, but included for consistency)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 5: Train the Decision Tree model\n",
    "# We can fine-tune parameters like max_depth, min_samples_split, etc., to avoid overfitting\n",
    "tree_model = DecisionTreeClassifier(random_state=521998, max_depth=10)  # You can adjust max_depth or other hyperparameters\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = tree_model.predict(X_test_scaled)\n",
    "\n",
    "# Step 7: Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load dataset with document embeddings\n",
    "df = pd.read_csv('/Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/doc2vec_embeddings.csv', sep=\",\") # not in German\n",
    "# df = pd.read_csv('/Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/bert_embeddings.csv', sep=\",\") # when using BERT embeddings in German!\n",
    "\n",
    "# Define a function to safely parse the embedding strings into lists of floats\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (Doc2Vec embeddings) and target (counter)\n",
    "X = df['doc2vec_embeddings'].apply(parse_embedding_string).tolist()  # Document embeddings\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test), stratifying by class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=521998, stratify=y)\n",
    "\n",
    "# Step 4: Standardize the embeddings (SVM is sensitive to feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 5: Train the Support Vector Machine (SVM) model\n",
    "# Using a linear kernel, but we can also experiment with other kernels like 'rbf' or 'poly'\n",
    "svm_model = SVC(kernel='linear', C=1.0, probability=True)  # C is the regularization parameter (similar to logistic regression)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Step 7: Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1: Load dataset with document embeddings\n",
    "df = pd.read_csv('/Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/doc2vec_embeddings.csv', sep=\",\") # not in German\n",
    "\n",
    "# Define a function to safely parse the embedding strings into lists of floats\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (Doc2Vec embeddings) and target (counter)\n",
    "X = df['doc2vec_embeddings'].apply(parse_embedding_string).tolist()  # Document embeddings\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test), stratifying by class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=521998, stratify=y)\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=521998)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Standardize the embeddings (SVM is sensitive to feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 6: Train the Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear', C=0.1, probability=True)  # note higher regularization if we decrease C\n",
    "svm_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Step 8: Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat better, but still poor performance... Let's try with the BERT model optimal for German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Step 1: Load dataset with document embeddings\n",
    "df = pd.read_csv('/Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/bert_embeddings.csv', sep=\",\") #in German\n",
    "\n",
    "# Define a function to safely parse the embedding strings into lists of floats\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (Doc2Vec embeddings) and target (counter)\n",
    "X = df['bert_embeddings'].apply(parse_embedding_string).tolist()  # Document embeddings\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test), stratifying by class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=521998, stratify=y)\n",
    "\n",
    "# Step 4: Apply random oversampling to the training set\n",
    "oversampler = RandomOverSampler(random_state=521998)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Standardize the embeddings (SVM is sensitive to feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 6: Train the Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear', C=0.1, probability=True)  # note higher regularization if we decrease C\n",
    "svm_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Step 7: Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Step 8: Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Classification with OpenAI's GPT-4 model (via API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macanovic & Przepiorka (2024): On the Hate speech dataset, GPT-4 in particular performs on par with fine-tuned transformer models, suggesting that zero-shot classification can handle some tasks rather well. Providing GPT-4 with more thorough instructions akin to those in extensive coding schemes could potentially lead to further improvement in its performance (see Figure E9 in Appendix E).\n",
    "\n",
    "Moreover, as the authors noted, \"When working with zero-shot classification models, we do not conduct any particular data preparation steps; any pre-processing happens on the model side when using the API. We feed the raw textual data to the OpenAI API.\" This is crucial because it alleviates a lot of work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try with GPT-4 (the most powerful tool). Then, we could try GPT-3.5. Finally, in the next section we would try with zero-shot classification with original (not preprocessed) comments. \n",
    "\n",
    "We should also think about batch API to avoid tokens limits. **Batch Processing** involves grouping multiple comments into a single request, which can save time and might also reduce the number of total API calls:\n",
    "* It is efficient, especially when we need to classify a large number of comments quickly.\n",
    "* However, there's a limit to how much content we can put into a single request because of the context window (e.g. 8,192 tokens for GPT-4). So it can fit multiple comments per request within the model’s token limit. Otherwise, we could use **rate limiting** if you need to submit individual requests over a longer duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE BY Macanovic & Przepiorka (2024):\n",
    "\n",
    "\"The texts you are evaluating come from online marketplaces that specialize in illegal goods. You'll receive feedback texts, in German, one at a time.\n",
    "\n",
    "Please denote whether each text contains traces of:\n",
    "1. hate speech\n",
    "2. offensive language\n",
    "3. neither hate speech nor offensive language\n",
    "Each text can belong to only one of these categories.\n",
    "\n",
    "I'm now going to show you the text to be analysed: {phrase}.\n",
    "\n",
    "Give your answer in the following form, without further comment: {{ 'label' : 0 }} for 'hate speech'; {{ 'label' : 1 }} for 'offensive language'; {{ 'label' : 2 }} for 'neither hate speech nor offensive language'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUR EXAMPLE of INPUT PROMPT:\n",
    "The texts you are evaluating are written in German and come from an online platform like Twitter, focusing on topics such as LGTBIQ+ rights, ecologism, and others.\n",
    "\n",
    "Please denote whether each text is:\n",
    "1. counterspeech\n",
    "2. not counterspeech\n",
    "\n",
    "I'm now going to show you the text to be analyzed: \"{comment}\".\n",
    "\n",
    "Give your answer in the following form, without further comment: {{ 'label' : 0 }} for 'not counterspeech'; {{ 'label' : 1 }} for 'counterspeech'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens (including input prompt and response tokens) for classification: 417653\n",
      "Estimated cost for classifying comments: $12.53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "df = pd.read_csv(\"counterspeech/df_cleaned.csv\", sep = \",\")\n",
    "\n",
    "# Initialize the tokenizer for GPT-4\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "# Define the input prompt\n",
    "input_prompt = \"\"\"Die Texte, die Sie bewerten, sind auf Deutsch geschrieben und stammen von einer Online-Plattform wie Twitter. Sie befassen sich mit Themen wie LGTBI-Rechten, Ökologie und anderen.\n",
    "\n",
    "Bitte geben Sie an, ob jeder Text:\n",
    "\n",
    "1. Gegenrede ist\n",
    "2. Keine Gegenrede ist\n",
    "\n",
    "Ich werde Ihnen nun den zu analysierenden Text zeigen: \"{comment}\".\n",
    "\n",
    "Geben Sie Ihre Antwort in folgender Form, ohne weiteren Kommentar: {{ 'label' : 0 }} für 'keine Gegenrede'; {{ 'label' : 1 }} für 'Gegenrede'.\"\"\"\n",
    "\n",
    "# Tokenize the input prompt (without the actual comment placeholder)\n",
    "prompt_tokens = len(tokenizer.encode(input_prompt.replace(\"{comment}\", \"\")))\n",
    "\n",
    "# Number of tokens for the response (typically 2-3 tokens for 'label' : 0 or 'label' : 1)\n",
    "response_tokens = 3  # Estimated output tokens\n",
    "\n",
    "# Estimate the number of tokens for each comment including the input prompt and response\n",
    "df['num_tokens'] = df['comment'].apply(lambda x: len(tokenizer.encode(x)) + prompt_tokens + response_tokens)\n",
    "\n",
    "# Sum the tokens to get the total number of tokens\n",
    "total_tokens = df['num_tokens'].sum()\n",
    "\n",
    "# Display the total token count\n",
    "print(f\"Total number of tokens (including input prompt and response tokens) for classification: {total_tokens}\")\n",
    "\n",
    "# Display the estimated cost for the tokens (GPT-4 charges $0.03 per 1k input tokens)\n",
    "cost_per_1k_tokens = 0.03\n",
    "estimated_cost = (total_tokens / 1000) * cost_per_1k_tokens\n",
    "print(f\"Estimated cost for classifying comments: ${estimated_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2399.000000\n",
      "mean       92.617757\n",
      "std        64.447367\n",
      "min         2.000000\n",
      "25%        48.000000\n",
      "50%        80.000000\n",
      "75%       123.000000\n",
      "max       619.000000\n",
      "Name: comment_length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['comment_length'] = df['comment_cleaned'].apply(len)\n",
    "print(df['comment_length'].describe())\n",
    "df['comment_length'].hist(bins=50)\n",
    "long_comments = df[df['comment_length'] > df['comment_length'].quantile(0.95)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>counter</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>language</th>\n",
       "      <th>comment_lemmatized</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>Ich finde, jeder Mensch sollte selbst entschei...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>finde mensch entscheiden oder er leben verbrin...</td>\n",
       "      <td>german</td>\n",
       "      <td>finden mensch entscheiden oder er leben verbri...</td>\n",
       "      <td>328</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>Ich schließe mich Wundertüte an. Wenn sie Gott...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>schliesse wundertuete gott kennen waeren nicht...</td>\n",
       "      <td>german</td>\n",
       "      <td>schließ wundertuen gott kennen waeren nicht NA...</td>\n",
       "      <td>335</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>Ich habe grundsätzlich nichts gegen Transgende...</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>grundsaetzlich transgender mensch er moechte p...</td>\n",
       "      <td>german</td>\n",
       "      <td>grundsaetzlich transgender mensch er moecht po...</td>\n",
       "      <td>259</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>Ich weiß nicht ob Transgender etwas im Militär...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>weiss nicht ob transgender militaer suchen ehr...</td>\n",
       "      <td>german</td>\n",
       "      <td>weiß nicht ob transgend militaer suchen ehrlic...</td>\n",
       "      <td>219</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>Ich finde Gleichberechtigung auch wichtig und ...</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>finde gleichberechtigung wichtig und eigentlic...</td>\n",
       "      <td>german</td>\n",
       "      <td>finden gleichberechtigung wichtig und eigentli...</td>\n",
       "      <td>215</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>2379</td>\n",
       "      <td>Ich kann den Kommentar von Utopianuser nicht n...</td>\n",
       "      <td>0</td>\n",
       "      <td>2404</td>\n",
       "      <td>kommentar utopianuser nicht nachvollziehen seh...</td>\n",
       "      <td>german</td>\n",
       "      <td>kommentar utopianuser nicht nachvollziehen seh...</td>\n",
       "      <td>409</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>2384</td>\n",
       "      <td>@ Seeannemone   Und dann? Wenn alle Geflohenen...</td>\n",
       "      <td>0</td>\n",
       "      <td>2409</td>\n",
       "      <td>seeannemone und geflohenen eu verlassen magisc...</td>\n",
       "      <td>german</td>\n",
       "      <td>seeannemon und geflohen eu verlassen magisch a...</td>\n",
       "      <td>281</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>2386</td>\n",
       "      <td>Ich glaube hier ist es wichtig einen Kontext f...</td>\n",
       "      <td>0</td>\n",
       "      <td>2411</td>\n",
       "      <td>glaube wichtig kontext gewalt skizzieren haeuf...</td>\n",
       "      <td>german</td>\n",
       "      <td>glauben wichtig kontext walen skizzi haeufig w...</td>\n",
       "      <td>290</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2395</td>\n",
       "      <td>Ich bitte euch darum dieses Bild genau anzuseh...</td>\n",
       "      <td>0</td>\n",
       "      <td>2421</td>\n",
       "      <td>bitte euch bild genau anzusehen menschen schle...</td>\n",
       "      <td>german</td>\n",
       "      <td>bitten ihr bild genau ansehen mensch schlecht ...</td>\n",
       "      <td>240</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>Ich kann usercfor nicht zustimmen. Ich sehe ke...</td>\n",
       "      <td>0</td>\n",
       "      <td>2424</td>\n",
       "      <td>usercfor nicht zustimmen sehe keine wuetenden ...</td>\n",
       "      <td>german</td>\n",
       "      <td>usercfor nicht zustimmen sehe kein wuetend flu...</td>\n",
       "      <td>332</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  counter  \\\n",
       "40            41  Ich finde, jeder Mensch sollte selbst entschei...        0   \n",
       "67            68  Ich schließe mich Wundertüte an. Wenn sie Gott...        0   \n",
       "100          101  Ich habe grundsätzlich nichts gegen Transgende...        0   \n",
       "107          108  Ich weiß nicht ob Transgender etwas im Militär...        0   \n",
       "127          128  Ich finde Gleichberechtigung auch wichtig und ...        0   \n",
       "...          ...                                                ...      ...   \n",
       "2378        2379  Ich kann den Kommentar von Utopianuser nicht n...        0   \n",
       "2383        2384  @ Seeannemone   Und dann? Wenn alle Geflohenen...        0   \n",
       "2385        2386  Ich glaube hier ist es wichtig einen Kontext f...        0   \n",
       "2394        2395  Ich bitte euch darum dieses Bild genau anzuseh...        0   \n",
       "2397        2398  Ich kann usercfor nicht zustimmen. Ich sehe ke...        0   \n",
       "\n",
       "        id                                    comment_cleaned language  \\\n",
       "40      41  finde mensch entscheiden oder er leben verbrin...   german   \n",
       "67      68  schliesse wundertuete gott kennen waeren nicht...   german   \n",
       "100    104  grundsaetzlich transgender mensch er moechte p...   german   \n",
       "107    111  weiss nicht ob transgender militaer suchen ehr...   german   \n",
       "127    131  finde gleichberechtigung wichtig und eigentlic...   german   \n",
       "...    ...                                                ...      ...   \n",
       "2378  2404  kommentar utopianuser nicht nachvollziehen seh...   german   \n",
       "2383  2409  seeannemone und geflohenen eu verlassen magisc...   german   \n",
       "2385  2411  glaube wichtig kontext gewalt skizzieren haeuf...   german   \n",
       "2394  2421  bitte euch bild genau anzusehen menschen schle...   german   \n",
       "2397  2424  usercfor nicht zustimmen sehe keine wuetenden ...   german   \n",
       "\n",
       "                                     comment_lemmatized  comment_length  \\\n",
       "40    finden mensch entscheiden oder er leben verbri...             328   \n",
       "67    schließ wundertuen gott kennen waeren nicht NA...             335   \n",
       "100   grundsaetzlich transgender mensch er moecht po...             259   \n",
       "107   weiß nicht ob transgend militaer suchen ehrlic...             219   \n",
       "127   finden gleichberechtigung wichtig und eigentli...             215   \n",
       "...                                                 ...             ...   \n",
       "2378  kommentar utopianuser nicht nachvollziehen seh...             409   \n",
       "2383  seeannemon und geflohen eu verlassen magisch a...             281   \n",
       "2385  glauben wichtig kontext walen skizzi haeufig w...             290   \n",
       "2394  bitten ihr bild genau ansehen mensch schlecht ...             240   \n",
       "2397  usercfor nicht zustimmen sehe kein wuetend flu...             332   \n",
       "\n",
       "      num_tokens  \n",
       "40           260  \n",
       "67           258  \n",
       "100          247  \n",
       "107          220  \n",
       "127          200  \n",
       "...          ...  \n",
       "2378         294  \n",
       "2383         239  \n",
       "2385         271  \n",
       "2394         220  \n",
       "2397         269  \n",
       "\n",
       "[120 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_comments = df[df['comment_length'] > df['comment_length'].quantile(0.95)]\n",
    "long_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presence of long comments means that token usage may vary significantly for different requests. Long comments could consume a disproportionate number of tokens, especially when combined with the input prompt and the expected output explanation.\n",
    "Given the token limits of 10,000 TPM for GPT-4, the variability in comment length means that conservative token estimation is crucial to prevent exceeding rate limits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **SOME NOTES BEFORE RUNNING ZERO-SHOT CLASSIFICATION**\n",
    "\n",
    "1. **Timeout handling and entries**: By setting a timeout and retry mechanism, we ensure that our process doesn’t halt due to occasional delays or interruptions. If the model doesn’t respond in a reasonable time, retrying ensures that we don’t miss classifications. Assigning a fallback (e.g. marking as not counterspeech) for texts that still fail after retries is crucial for maintaining workflow continuity without introducing errors due to missing responses. We will follow Macanovic & Przepiorka (2024): \"We wait for the model to return the output for 20 seconds; if this timeout is exceeded, we retry up to 2 more times, after which we denote text as not containing any coding categories\".\n",
    "* A **try-except block** is used to handle exceptions or errors in Python. When working with the API, there’s always a risk that a request might fail (e.g., rate limit exceeded, connection errors, etc.). Using a try-except block helps ensure that a single failed request does *not* cause the entire script to crash. Instead, we can catch the error, log it, and then either retry the request (as *NA* for instance) or move on to the next comment. This ensures the process continues running smoothly even if there are occasional failures.\n",
    "2. **Rate limit with timer**: OpenAI API has rate limits, which define the number of requests we can make per minute, especially important when working with large batches of data. By spacing out requests, we ensure we do not exceed token limits or rate limits, which can result in request failures. Adding delays can prevent hitting the token or request limit, allowing smoother processing. This can be handled by adding a time.`sleep(15)` after each API request. **However, we must verify our plan’s rate limits before proceeding, as the limits can vary depending on the type of subscription we have with OpenAI**.\n",
    "3. Framing it as a \"**research assistant**\" ensures that the model understands the task in a professional and consistent manner, which can lead to more accurate and contextually aware responses. This technique has been found to improve consistency in how the model follows instructions. This is specified in the role of the model in English, although the input will be in German for consistency!\n",
    "4. **Monitoring token consumption**: Implement logging to track token usage per request and overall cost, to ensure we stay within budget limits. Use OpenAI's token consumption endpoint or keep a manual log. Every time a request is sent to the API, log the number of tokens used (including both input and output). We can use the len() function to calculate tokens in the input prompt, comment, and output response to approximate token usage for each request.\n",
    "5. **Batch size**: WE send a number of comments together in each request to API (*not one comment at a time*). To manage the API usage efficiently and ensure that we do not overwhelm the system, we should pace the requests appropriately, perhaps sending them with a short delay in between (e.g. every 2-3 seconds) to reduce the risk of hitting rate limits or causing server issues. This could help speed up the classification process and reduce the load on the API. However, each batch size should fit within the **8,192-token limit** for GPT-4 or 4,096 tokens for GPT-4 Turbo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  15%|█▍        | 22/150 [13:55<1:26:22, 40.49s/it]2024-10-24 19:05:42,340 - ERROR - Error generating classification: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Processing Batches:  15%|█▌        | 23/150 [44:54<20:40:53, 586.25s/it]2024-10-24 21:08:04,884 - ERROR - Error generating classification: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "Processing Batches: 100%|██████████| 150/150 [4:06:05<00:00, 98.44s/it]    \n",
      "2024-10-24 22:27:40,056 - INFO - Processing complete. Results saved to df_classified_gpt4_turbo.csv.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "\n",
    "# Step 1: Set up OpenAI API key\n",
    "openai.api_key = '' # include your API key here\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "df = pd.read_csv(\"counterspeech/df_cleaned.csv\", sep = \",\")\n",
    "\n",
    "# Step 3: Set up logging for monitoring\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Step 4: Prepare the prompt template in German\n",
    "input_prompt = \"\"\"Die Texte, die Sie bewerten, sind auf Deutsch geschrieben und stammen von einer Online-Plattform wie Twitter. Sie befassen sich mit Themen wie LGTBI-Rechten, Ökologie und anderen.\n",
    "\n",
    "Bitte geben Sie an, ob jeder Text:\n",
    "\n",
    "1. Gegenrede ist\n",
    "2. Keine Gegenrede ist\n",
    "\n",
    "Ich werde Ihnen nun den zu analysierenden Text zeigen: \"{comment}\".\n",
    "\n",
    "Geben Sie Ihre Antwort in folgender Form, ohne weiteren Kommentar: {{'label' : 0}} für 'keine Gegenrede'; {{'label' : 1}} für 'Gegenrede'.\"\"\"\n",
    "\n",
    "# Step 5: Set up a retry mechanism to handle timeouts and API errors\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(20))\n",
    "def get_classification(comment):\n",
    "    prompt = input_prompt.format(comment=comment)\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a research assistant at a German university.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10,  # Limit tokens for concise responses\n",
    "            temperature=0  # Make output deterministic\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating classification: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 6: Batch processing the comments\n",
    "batch_size = 16  # Number of comments per batch\n",
    "num_batches = len(df) // batch_size + (1 if len(df) % batch_size != 0 else 0)\n",
    "\n",
    "token_consumption = 0\n",
    "classifications = []\n",
    "\n",
    "for batch_idx in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "    batch_start = batch_idx * batch_size\n",
    "    batch_end = min((batch_idx + 1) * batch_size, len(df))\n",
    "    batch_comments = df['comment'][batch_start:batch_end]\n",
    "\n",
    "    batch_results = []\n",
    "    for comment in batch_comments:\n",
    "        try:\n",
    "            result = get_classification(comment)\n",
    "            batch_results.append(result)\n",
    "            token_consumption += len(comment.split()) + 10  # Approximate token count: comment + response\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to classify comment after retries: {e}\")\n",
    "            batch_results.append(\"{ 'label' : 0 }\")  # Default to 'not counterspeech' if all retries fail\n",
    "\n",
    "    classifications.extend(batch_results)\n",
    "    time.sleep(20)  # Wait 20 seconds between batches to avoid rate limits\n",
    "\n",
    "# Step 7: Add new labels to the dataframe and save\n",
    "output_file = '/Users/counterspeech/df_classified_gpt4_turbo.csv'\n",
    "df['counter_gpt4'] = classifications\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "logging.info(\"Processing complete. Results saved to df_classified_gpt4_turbo.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>counter</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>language</th>\n",
       "      <th>comment_lemmatized</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>counter_gpt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Schwule, die für ihre Rechte auf die Straße ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>schwule rechte strasse gehen schoen sehen frei...</td>\n",
       "      <td>german</td>\n",
       "      <td>schwul rechte strassen gehen scho sehen freihe...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'label' : 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ich nehme an das ist der Christopher Street Da...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nehme christopher street day oae asiatischen l...</td>\n",
       "      <td>german</td>\n",
       "      <td>nehmen christopher streen day oa asiatischen l...</td>\n",
       "      <td>19</td>\n",
       "      <td>{'label' : 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Solange Homosexuelle nicht in allen Ländern si...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>solange homosexuelle nicht allen laendern sich...</td>\n",
       "      <td>german</td>\n",
       "      <td>solange homosexuell nicht alle laendern sicher...</td>\n",
       "      <td>18</td>\n",
       "      <td>{'label' : 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Homosexualität wird in unserer Gesellschaft of...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>homosexualitaet gesellschaft oftmals gegeissel...</td>\n",
       "      <td>german</td>\n",
       "      <td>homosexualitaen sellschafen oftmals gegeisselt...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'label' : 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Echt schade, dass dafür extra eine Parade stat...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>echt schade dafuer extra parade finden und nic...</td>\n",
       "      <td>german</td>\n",
       "      <td>echt schade dafuer extra parade finden und nic...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'label' : 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2395</td>\n",
       "      <td>Ich bitte euch darum dieses Bild genau anzuseh...</td>\n",
       "      <td>0</td>\n",
       "      <td>2421</td>\n",
       "      <td>bitte euch bild genau anzusehen menschen schle...</td>\n",
       "      <td>german</td>\n",
       "      <td>bitten ihr bild genau ansehen mensch schlecht ...</td>\n",
       "      <td>33</td>\n",
       "      <td>{'label' : 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2396</td>\n",
       "      <td>Wie kannst du nur so etwas behaupten, Wintergr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2422</td>\n",
       "      <td>du behaupten wintergruen meisten unendliches l...</td>\n",
       "      <td>german</td>\n",
       "      <td>du behaupten wintergruen meist unendlich leid ...</td>\n",
       "      <td>11</td>\n",
       "      <td>{'label' : 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2397</td>\n",
       "      <td>Gartenzaunvorstand, zu bist so einseitig. Sie ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2423</td>\n",
       "      <td>gartenzaunvorstand einseitig laufen neuen hoff...</td>\n",
       "      <td>german</td>\n",
       "      <td>gartenzaunvorstehen einseitig laufen neu hoffe...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'label' : 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>Ich kann usercfor nicht zustimmen. Ich sehe ke...</td>\n",
       "      <td>0</td>\n",
       "      <td>2424</td>\n",
       "      <td>usercfor nicht zustimmen sehe keine wuetenden ...</td>\n",
       "      <td>german</td>\n",
       "      <td>usercfor nicht zustimmen sehe kein wuetend flu...</td>\n",
       "      <td>40</td>\n",
       "      <td>{'label' : 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2399</td>\n",
       "      <td>man sieht auf dem Foto echt nicht viel, auserd...</td>\n",
       "      <td>0</td>\n",
       "      <td>2425</td>\n",
       "      <td>man sieht foto echt nicht viel auserdem allerw...</td>\n",
       "      <td>german</td>\n",
       "      <td>man sehen foto echt nicht viel auserdem allerw...</td>\n",
       "      <td>20</td>\n",
       "      <td>{'label' : 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  counter  \\\n",
       "0              1  Schwule, die für ihre Rechte auf die Straße ge...        0   \n",
       "1              2  Ich nehme an das ist der Christopher Street Da...        0   \n",
       "2              3  Solange Homosexuelle nicht in allen Ländern si...        0   \n",
       "3              4  Homosexualität wird in unserer Gesellschaft of...        0   \n",
       "4              5  Echt schade, dass dafür extra eine Parade stat...        0   \n",
       "...          ...                                                ...      ...   \n",
       "2394        2395  Ich bitte euch darum dieses Bild genau anzuseh...        0   \n",
       "2395        2396  Wie kannst du nur so etwas behaupten, Wintergr...        1   \n",
       "2396        2397  Gartenzaunvorstand, zu bist so einseitig. Sie ...        0   \n",
       "2397        2398  Ich kann usercfor nicht zustimmen. Ich sehe ke...        0   \n",
       "2398        2399  man sieht auf dem Foto echt nicht viel, auserd...        0   \n",
       "\n",
       "        id                                    comment_cleaned language  \\\n",
       "0        1  schwule rechte strasse gehen schoen sehen frei...   german   \n",
       "1        2  nehme christopher street day oae asiatischen l...   german   \n",
       "2        3  solange homosexuelle nicht allen laendern sich...   german   \n",
       "3        4  homosexualitaet gesellschaft oftmals gegeissel...   german   \n",
       "4        5  echt schade dafuer extra parade finden und nic...   german   \n",
       "...    ...                                                ...      ...   \n",
       "2394  2421  bitte euch bild genau anzusehen menschen schle...   german   \n",
       "2395  2422  du behaupten wintergruen meisten unendliches l...   german   \n",
       "2396  2423  gartenzaunvorstand einseitig laufen neuen hoff...   german   \n",
       "2397  2424  usercfor nicht zustimmen sehe keine wuetenden ...   german   \n",
       "2398  2425  man sieht foto echt nicht viel auserdem allerw...   german   \n",
       "\n",
       "                                     comment_lemmatized  comment_length  \\\n",
       "0     schwul rechte strassen gehen scho sehen freihe...              10   \n",
       "1     nehmen christopher streen day oa asiatischen l...              19   \n",
       "2     solange homosexuell nicht alle laendern sicher...              18   \n",
       "3     homosexualitaen sellschafen oftmals gegeisselt...               7   \n",
       "4     echt schade dafuer extra parade finden und nic...              10   \n",
       "...                                                 ...             ...   \n",
       "2394  bitten ihr bild genau ansehen mensch schlecht ...              33   \n",
       "2395  du behaupten wintergruen meist unendlich leid ...              11   \n",
       "2396  gartenzaunvorstehen einseitig laufen neu hoffe...               7   \n",
       "2397  usercfor nicht zustimmen sehe kein wuetend flu...              40   \n",
       "2398  man sehen foto echt nicht viel auserdem allerw...              20   \n",
       "\n",
       "       counter_gpt4  \n",
       "0     {'label' : 0}  \n",
       "1     {'label' : 0}  \n",
       "2     {'label' : 0}  \n",
       "3     {'label' : 0}  \n",
       "4     {'label' : 1}  \n",
       "...             ...  \n",
       "2394  {'label' : 1}  \n",
       "2395  {'label' : 1}  \n",
       "2396  {'label' : 0}  \n",
       "2397  {'label' : 1}  \n",
       "2398  {'label' : 0}  \n",
       "\n",
       "[2399 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"/Users/tonigamundi/Desktop/Counterspeech-Amalia/counterspeech/df_classified_gpt4_turbo.csv\", sep = \",\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Precision: 0.26\n",
      "Recall: 0.48\n",
      "F1 Score: 0.33\n",
      "Confusion Matrix:\n",
      "[[1968  251]\n",
      " [  94   86]]\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Not Counterspeech       0.95      0.89      0.92      2219\n",
      "    Counterspeech       0.26      0.48      0.33       180\n",
      "\n",
      "         accuracy                           0.86      2399\n",
      "        macro avg       0.60      0.68      0.63      2399\n",
      "     weighted avg       0.90      0.86      0.88      2399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Extract the GPT-4 labels and convert them to integers\n",
    "df2['counter_gpt4'] = df2['counter_gpt4'].apply(lambda x: int(x.strip(\"{'label' : }\")))\n",
    "\n",
    "# Step 2: Prepare the true labels and predicted labels\n",
    "y_true = df2['counter']  # True labels from human coders\n",
    "y_pred = df2['counter_gpt4']  # Predicted labels from GPT-4-turbo\n",
    "\n",
    "# Step 3: Evaluate the model\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_true, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>counter</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_cleaned</th>\n",
       "      <th>language</th>\n",
       "      <th>comment_lemmatized</th>\n",
       "      <th>comment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Schwule, die für ihre Rechte auf die Straße ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>schwule rechte strasse gehen schoen sehen frei...</td>\n",
       "      <td>german</td>\n",
       "      <td>schwul rechte strassen gehen scho sehen freihe...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ich nehme an das ist der Christopher Street Da...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>nehme christopher street day oae asiatischen l...</td>\n",
       "      <td>german</td>\n",
       "      <td>nehmen christopher streen day oa asiatischen l...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Solange Homosexuelle nicht in allen Ländern si...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>solange homosexuelle nicht allen laendern sich...</td>\n",
       "      <td>german</td>\n",
       "      <td>solange homosexuell nicht alle laendern sicher...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Homosexualität wird in unserer Gesellschaft of...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>homosexualitaet gesellschaft oftmals gegeissel...</td>\n",
       "      <td>german</td>\n",
       "      <td>homosexualitaen sellschafen oftmals gegeisselt...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Echt schade, dass dafür extra eine Parade stat...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>echt schade dafuer extra parade finden und nic...</td>\n",
       "      <td>german</td>\n",
       "      <td>echt schade dafuer extra parade finden und nic...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2395</td>\n",
       "      <td>Ich bitte euch darum dieses Bild genau anzuseh...</td>\n",
       "      <td>0</td>\n",
       "      <td>2421</td>\n",
       "      <td>bitte euch bild genau anzusehen menschen schle...</td>\n",
       "      <td>german</td>\n",
       "      <td>bitten ihr bild genau ansehen mensch schlecht ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2396</td>\n",
       "      <td>Wie kannst du nur so etwas behaupten, Wintergr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2422</td>\n",
       "      <td>du behaupten wintergruen meisten unendliches l...</td>\n",
       "      <td>german</td>\n",
       "      <td>du behaupten wintergruen meist unendlich leid ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>2397</td>\n",
       "      <td>Gartenzaunvorstand, zu bist so einseitig. Sie ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2423</td>\n",
       "      <td>gartenzaunvorstand einseitig laufen neuen hoff...</td>\n",
       "      <td>german</td>\n",
       "      <td>gartenzaunvorstehen einseitig laufen neu hoffe...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>Ich kann usercfor nicht zustimmen. Ich sehe ke...</td>\n",
       "      <td>0</td>\n",
       "      <td>2424</td>\n",
       "      <td>usercfor nicht zustimmen sehe keine wuetenden ...</td>\n",
       "      <td>german</td>\n",
       "      <td>usercfor nicht zustimmen sehe kein wuetend flu...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2399</td>\n",
       "      <td>man sieht auf dem Foto echt nicht viel, auserd...</td>\n",
       "      <td>0</td>\n",
       "      <td>2425</td>\n",
       "      <td>man sieht foto echt nicht viel auserdem allerw...</td>\n",
       "      <td>german</td>\n",
       "      <td>man sehen foto echt nicht viel auserdem allerw...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            comment  counter  \\\n",
       "0              1  Schwule, die für ihre Rechte auf die Straße ge...        0   \n",
       "1              2  Ich nehme an das ist der Christopher Street Da...        0   \n",
       "2              3  Solange Homosexuelle nicht in allen Ländern si...        0   \n",
       "3              4  Homosexualität wird in unserer Gesellschaft of...        0   \n",
       "4              5  Echt schade, dass dafür extra eine Parade stat...        0   \n",
       "...          ...                                                ...      ...   \n",
       "2394        2395  Ich bitte euch darum dieses Bild genau anzuseh...        0   \n",
       "2395        2396  Wie kannst du nur so etwas behaupten, Wintergr...        1   \n",
       "2396        2397  Gartenzaunvorstand, zu bist so einseitig. Sie ...        0   \n",
       "2397        2398  Ich kann usercfor nicht zustimmen. Ich sehe ke...        0   \n",
       "2398        2399  man sieht auf dem Foto echt nicht viel, auserd...        0   \n",
       "\n",
       "        id                                    comment_cleaned language  \\\n",
       "0        1  schwule rechte strasse gehen schoen sehen frei...   german   \n",
       "1        2  nehme christopher street day oae asiatischen l...   german   \n",
       "2        3  solange homosexuelle nicht allen laendern sich...   german   \n",
       "3        4  homosexualitaet gesellschaft oftmals gegeissel...   german   \n",
       "4        5  echt schade dafuer extra parade finden und nic...   german   \n",
       "...    ...                                                ...      ...   \n",
       "2394  2421  bitte euch bild genau anzusehen menschen schle...   german   \n",
       "2395  2422  du behaupten wintergruen meisten unendliches l...   german   \n",
       "2396  2423  gartenzaunvorstand einseitig laufen neuen hoff...   german   \n",
       "2397  2424  usercfor nicht zustimmen sehe keine wuetenden ...   german   \n",
       "2398  2425  man sieht foto echt nicht viel auserdem allerw...   german   \n",
       "\n",
       "                                     comment_lemmatized  comment_length  \n",
       "0     schwul rechte strassen gehen scho sehen freihe...              10  \n",
       "1     nehmen christopher streen day oa asiatischen l...              19  \n",
       "2     solange homosexuell nicht alle laendern sicher...              18  \n",
       "3     homosexualitaen sellschafen oftmals gegeisselt...               7  \n",
       "4     echt schade dafuer extra parade finden und nic...              10  \n",
       "...                                                 ...             ...  \n",
       "2394  bitten ihr bild genau ansehen mensch schlecht ...              33  \n",
       "2395  du behaupten wintergruen meist unendlich leid ...              11  \n",
       "2396  gartenzaunvorstehen einseitig laufen neu hoffe...               7  \n",
       "2397  usercfor nicht zustimmen sehe kein wuetend flu...              40  \n",
       "2398  man sehen foto echt nicht viel auserdem allerw...              20  \n",
       "\n",
       "[2399 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"counterspeech/df_cleaned.csv\", sep = \",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected Counterspeech Examples for Few-Shot Prompt:\n",
    "\n",
    "Empathetic Rebuttal on Refugees and Empathy: \n",
    "* Comment: \"Ich finde die Kommentare einfach nur furchtbar. Wie kann man so herzlos sein gegenüber unseren Mitmenschen. Wir würden auch Hilfe wollen, wenn wir in der gleichen Situation wären.\"\n",
    "* Rationale: This comment uses empathy to counter negative attitudes toward refugees by inviting readers to consider themselves in a similar situation. It’s direct yet compassionate, making it a strong example of counterspeech that humanizes refugees.\n",
    "\n",
    "Rational Argument on Gender Identity and Societal Progress\n",
    "* Comment: \"Jeder sollte so sein, wie er sich fühlt. Ich verstehe es zwar auch nicht, aber man sollte sie respektieren. Quatschgerede mit Gott, mal ein bisschen mit der Zeit gehen und nicht noch im Jahr 1600 leben.\"\n",
    "* Rationale: Here, the commenter encourages tolerance toward gender expression and dismisses outdated beliefs. The comment shows rational support for diversity and progressiveness, making it a fitting example of a logical counterspeech argument.\n",
    "\n",
    "Supportive Counterspeech on Same-Sex Parenting\n",
    "* Comment: \"Warum sollten zwei Männer nicht in der Lage sein, ein Kind großzuziehen? Es gibt so viele Kinder, die in schwierigen Verhältnissen aufwachsen, wo Mutter und Vater ständig streiten oder keine Zeit für den Nachwuchs aufbringen. Wichtig ist, dass ein Kind geliebt wird und in einem intakten Umfeld aufwächst, egal ob das aus zwei Männern besteht oder nicht.\"\n",
    "* Rationale: This comment supports same-sex parenting by arguing that love and a stable environment are more important for a child than traditional family structures. It addresses a common social bias with evidence-based reasoning.\n",
    "\n",
    "Moral Appeal on LGBTQ+ Rights and Freedom\n",
    "* Comment: \"Alle sollten wen oder was lieben dürfen, was sie möchten. Das Wichtigste in unserem kurzen Leben ist es doch, glücklich zu sein. Wie kann man denn den Anblick des Glückes anderer Menschen eklig finden?\"\n",
    "* Rationale: This comment highlights freedom and the right to happiness, challenging those who find same-sex affection objectionable. It’s a powerful example of counterspeech that appeals to universal human rights and happiness.\n",
    "\n",
    "Critique of Misconceptions on Refugees and Criminality\n",
    "* Comment: \"Ihr übertreibt mit euren Hasskommentaren. Keiner von euch kennt einen auf dem Foto, aber gleich unterstellt ihr ihnen schlechte Motive.\"\n",
    "* Rationale: This comment directly counters unfounded prejudices by pointing out the assumption of negative motives without knowledge. It demonstrates a calm, fact-based approach to dispelling misconceptions, showing a different counterspeech strategy.\n",
    "\n",
    "Each comment provides a unique way of countering hate, from empathy and moral appeals to rational arguments and critiques of bias. Also, these comments are concise yet articulate, making them suitable for few-shot prompting without using excessive tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Prompt:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tiktoken\n",
    "import tiktoken\n",
    "\n",
    "# Initialize tokenizer for text-embedding-ada-002\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Example to estimate total tokens in your dataset\n",
    "total_tokens = sum(len(tokenizer.encode(comment)) for comment in df['comment'])\n",
    "print(f\"Total tokens: {total_tokens}\")\n",
    "\n",
    "# This means 5.88$ for 58752 tokens. So about 12$ for word and document embeddings in total.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH API (see OpenAI documentation: https://platform.openai.com/docs/guides/batch/getting-started). Why?\n",
    "\n",
    "Rate limits are measured in five ways: RPM (requests per minute), RPD (requests per day), TPM (tokens per minute), TPD (tokens per day), and IPM (images per minute). Rate limits can be hit across any of the options depending on what occurs first. For example, you might send 20 requests with only 100 tokens to the ChatCompletions endpoint and that would fill your limit (if your RPM was 20), even if you did not send 150k tokens (if your TPM limit was 150k) within those 20 requests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings using OpenAI's text-embedding-ada-002 (via API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai tqdm\n",
    "import openai  #to access API\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm  #for a progress bar (optional)\n",
    "\n",
    "# Step 2: Set up OpenAI API key\n",
    "openai.api_key = '' # include you API key for replication\n",
    "\n",
    "# Step 3: Load the dataset\n",
    "df = pd.read_csv(\"counterspeech/df_cleaned.csv\", sep = \",\")\n",
    "df_filtered = df[['id', 'comment_cleaned']]\n",
    "\n",
    "# Step 4: Function to get embeddings from OpenAI\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    try:\n",
    "        response = openai.Embedding.create(input=text, model=model)\n",
    "        embedding = response['data'][0]['embedding']\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 5: Generate embeddings for each cleaned comment\n",
    "embeddings = []\n",
    "for comment in tqdm(df_filtered['comment_cleaned'], desc=\"Generating Embeddings\"):\n",
    "    embedding = get_embedding(comment)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Step 6: Store embeddings in the dataframe\n",
    "df_filtered['embedding'] = embeddings\n",
    "\n",
    "# Step 7: Save the dataframe with embeddings for later use\n",
    "df_filtered.to_csv('document_embeddings_openai.csv', index=False)\n",
    "\n",
    "print(\"Embeddings have been successfully generated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                    comment_cleaned  \\\n",
      "0   1  schwule rechte strasse gehen schoen sehen frei...   \n",
      "1   2  nehme christopher street day oae asiatischen l...   \n",
      "2   3  solange homosexuelle nicht allen laendern sich...   \n",
      "3   4  homosexualitaet gesellschaft oftmals gegeissel...   \n",
      "4   5  echt schade dafuer extra parade finden und nic...   \n",
      "\n",
      "                                           embedding  counter  \n",
      "0  [0.011761805042624474, -0.01152750663459301, 0...        0  \n",
      "1  [0.007596342824399471, -0.003047893987968564, ...        0  \n",
      "2  [-0.004874377511441708, -0.006366932298988104,...        0  \n",
      "3  [0.0003481853927951306, 0.0063161905854940414,...        0  \n",
      "4  [-0.0030210288241505623, -0.017139380797743797...        0  \n"
     ]
    }
   ],
   "source": [
    "df_embeddings = pd.read_csv(\"counterspeech/document_embeddings_openai.csv\")\n",
    "df_cleaned = pd.read_csv(\"counterspeech/df_cleaned.csv\", sep = \",\")\n",
    "\n",
    "# Merge the two datasets on the 'id' column\n",
    "df_merged = pd.merge(df_embeddings, df_cleaned[['id', 'counter']], on='id')\n",
    "\n",
    "# Save the merged dataset to a new CSV file\n",
    "df_merged.to_csv('df_cleaned_embedded_ada.csv', index=False)\n",
    "\n",
    "# Check the merged dataset\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('counterspeech/df_cleaned_embedded_ada.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Load the dataset with OpenAI embeddings\n",
    "df = pd.read_csv('counterspeech/df_cleaned_embedded_ada.csv')\n",
    "\n",
    "# Define a function to safely parse the embedding strings\n",
    "def parse_embedding_string(embedding_str):\n",
    "    return list(map(float, embedding_str.strip('[]').split()))\n",
    "\n",
    "# Step 2: Prepare the features (document embeddings) and target (counter)\n",
    "# Define a function to safely parse the embedding strings\n",
    "def parse_embedding_string(embedding_str):\n",
    "    # Remove brackets and split by commas, then convert each part to a float\n",
    "    return list(map(float, embedding_str.strip('[]').replace(',', '').split()))\n",
    "\n",
    "# Apply the function to convert the embeddings to lists of floats\n",
    "X = df['embedding'].apply(parse_embedding_string).tolist()\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9999999, stratify=y)\n",
    "\n",
    "# Step 4: Initialize and train a logistic regression model\n",
    "logreg = LogisticRegression(penalty=\"l1\",solver=\"liblinear\", max_iter=1000, class_weight='balanced') # Increased max_iter to ensure convergence + weights\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Load the dataset with document embeddings\n",
    "df = pd.read_csv('counterspeech/df_cleaned_embedded_ada.csv')\n",
    "\n",
    "# Define a function to parse the embedding strings\n",
    "def parse_embedding_string(embedding_str):\n",
    "    # Remove brackets and split by commas, then convert each part to a float\n",
    "    return list(map(float, embedding_str.strip('[]').replace(',', '').split()))\n",
    "\n",
    "# Step 2: Prepare the features (document embeddings) and target (counter)\n",
    "X = df['embedding'].apply(parse_embedding_string).tolist()\n",
    "y = df['counter']  # Target variable (counterspeech label)\n",
    "\n",
    "# Step 3: Split the data into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9999999, stratify=y)\n",
    "\n",
    "# Step 4: Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=9999999)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Initialize and train a logistic regression model\n",
    "logreg = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=1000, class_weight='balanced') # Increased max_iter to ensure convergence + weights\n",
    "logreg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 6: Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report:\\n{classification_report(y_test, y_pred, target_names=[\"Not Counterspeech\", \"Counterspeech\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hateful Speech Classifier (PART 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download German stopwords from NLTK if not already downloaded\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hateful/final_hateful.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2: Preprocess comments for Doc2Vec (tokenization is needed)\n",
    "df['comment_tokens'] = df['comment'].apply(lambda x: x.split())\n",
    "\n",
    "# Step 3: Tag each document for Doc2Vec\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df['comment_tokens'])]\n",
    "\n",
    "# Step 4: Train a Doc2Vec model\n",
    "# Initialize the Doc2Vec model\n",
    "doc2vec_model = Doc2Vec(vector_size=100, window=5, min_count=2, workers=4, epochs=40)\n",
    "doc2vec_model.build_vocab(documents)\n",
    "\n",
    "# Train the model on the documents\n",
    "doc2vec_model.train(documents, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "# Step 5: Generate document embeddings for each comment\n",
    "df['comment_embedding'] = df['comment_tokens'].apply(lambda x: doc2vec_model.infer_vector(x))\n",
    "\n",
    "# Step 6: Prepare data for Linear Regression\n",
    "# Extract embeddings into a separate DataFrame, converting each embedding list into columns\n",
    "embeddings = pd.DataFrame(df['comment_embedding'].tolist())\n",
    "\n",
    "# Set the target variable\n",
    "y = df['score']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Train a Linear Regression model using embeddings as predictors\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions and evaluate the model\n",
    "y_pred = linear_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r_squared}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 2: Preprocess comments for Doc2Vec (tokenization is needed)\n",
    "df['comment_tokens'] = df['comment'].apply(lambda x: x.split())\n",
    "\n",
    "# Step 3: Tag each document for Doc2Vec\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(df['comment_tokens'])]\n",
    "\n",
    "# Step 4: Train a Doc2Vec model\n",
    "doc2vec_model = Doc2Vec(vector_size=100, window=5, min_count=2, workers=4, epochs=40)\n",
    "doc2vec_model.build_vocab(documents)\n",
    "doc2vec_model.train(documents, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "# Step 5: Generate document embeddings for each comment\n",
    "df['comment_embedding'] = df['comment_tokens'].apply(lambda x: doc2vec_model.infer_vector(x))\n",
    "\n",
    "# Step 6: Prepare data for Linear Regression with additional covariates\n",
    "# Extract embeddings into a DataFrame, converting each embedding list into columns\n",
    "embeddings = pd.DataFrame(df['comment_embedding'].tolist())\n",
    "\n",
    "# Select the additional covariates as features and apply one-hot encoding to categorical variables\n",
    "covariates = df[['group', 'PropNA', 'state', 'education', 'employment', 'age', 'inhabitants', 'gender', 'East']]\n",
    "\n",
    "# Use one-hot encoding for categorical variables\n",
    "covariates = pd.get_dummies(covariates, drop_first=True)\n",
    "\n",
    "# Combine embeddings with covariates\n",
    "X = pd.concat([embeddings, covariates.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Convert all column names to strings to avoid any issues\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "# Set the target variable\n",
    "y = df['score']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Train a Linear Regression model using embeddings and covariates as predictors\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Make predictions and evaluate the model\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) and R-squared to assess improvement\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared: {r_squared}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10000</th>\n",
       "      <th>1000e</th>\n",
       "      <th>100x</th>\n",
       "      <th>1111</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>13jaehrige</th>\n",
       "      <th>14</th>\n",
       "      <th>150</th>\n",
       "      <th>15jaehrige</th>\n",
       "      <th>...</th>\n",
       "      <th>zwischendurch</th>\n",
       "      <th>zwischenfaellen</th>\n",
       "      <th>zwischenmenschliche</th>\n",
       "      <th>zwischenzeitlich</th>\n",
       "      <th>zwoelf</th>\n",
       "      <th>zynisch</th>\n",
       "      <th>zynische</th>\n",
       "      <th>zynismus</th>\n",
       "      <th>zypern</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11159</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11161 rows × 14784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10000  1000e  100x  1111   12   13  13jaehrige   14  150  15jaehrige  \\\n",
       "0        0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "1        0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "2        0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "3        0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "4        0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "...      ...    ...   ...   ...  ...  ...         ...  ...  ...         ...   \n",
       "11156    0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "11157    0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "11158    0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "11159    0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "11160    0.0    0.0   0.0   0.0  0.0  0.0         0.0  0.0  0.0         0.0   \n",
       "\n",
       "       ...  zwischendurch  zwischenfaellen  zwischenmenschliche  \\\n",
       "0      ...            0.0              0.0                  0.0   \n",
       "1      ...            0.0              0.0                  0.0   \n",
       "2      ...            0.0              0.0                  0.0   \n",
       "3      ...            0.0              0.0                  0.0   \n",
       "4      ...            0.0              0.0                  0.0   \n",
       "...    ...            ...              ...                  ...   \n",
       "11156  ...            0.0              0.0                  0.0   \n",
       "11157  ...            0.0              0.0                  0.0   \n",
       "11158  ...            0.0              0.0                  0.0   \n",
       "11159  ...            0.0              0.0                  0.0   \n",
       "11160  ...            0.0              0.0                  0.0   \n",
       "\n",
       "       zwischenzeitlich  zwoelf  zynisch  zynische  zynismus  zypern   zz  \n",
       "0                   0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "1                   0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "2                   0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "3                   0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "4                   0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "...                 ...     ...      ...       ...       ...     ...  ...  \n",
       "11156               0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "11157               0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "11158               0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "11159               0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "11160               0.0     0.0      0.0       0.0       0.0     0.0  0.0  \n",
       "\n",
       "[11161 rows x 14784 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "df = pd.read_csv('hateful/final_hateful_cleaned.csv')\n",
    "\n",
    "# Step 1: Generate TF-IDF Features (Unigrams)\n",
    "# Initialize the TF-IDF Vectorizer with unigrams only\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1))  # (1,1) specifies unigrams\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Convert the TF-IDF sparse matrix to a DataFrame for easier analysis\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        13   14   16  1945  1989  2015  20152016  2016  2017  2018  ...  \\\n",
      "0      0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "1      0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "2      0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "3      0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "4      0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "...    ...  ...  ...   ...   ...   ...       ...   ...   ...   ...  ...   \n",
      "11156  0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "11157  0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "11158  0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "11159  0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "11160  0.0  0.0  0.0   0.0   0.0   0.0       0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "       zweiweltkrieg  zwiegespalten  zwingen  zwingend  zwingt  zwinkern  \\\n",
      "0                0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "1                0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "2                0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "3                0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "4                0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "...              ...            ...      ...       ...     ...       ...   \n",
      "11156            0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "11157            0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "11158            0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "11159            0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "11160            0.0            0.0      0.0       0.0     0.0       0.0   \n",
      "\n",
      "       zwischendurch  zwischenmenschliche  zwischenzeitlich  zynisch  \n",
      "0                0.0                  0.0               0.0      0.0  \n",
      "1                0.0                  0.0               0.0      0.0  \n",
      "2                0.0                  0.0               0.0      0.0  \n",
      "3                0.0                  0.0               0.0      0.0  \n",
      "4                0.0                  0.0               0.0      0.0  \n",
      "...              ...                  ...               ...      ...  \n",
      "11156            0.0                  0.0               0.0      0.0  \n",
      "11157            0.0                  0.0               0.0      0.0  \n",
      "11158            0.0                  0.0               0.0      0.0  \n",
      "11159            0.0                  0.0               0.0      0.0  \n",
      "11160            0.0                  0.0               0.0      0.0  \n",
      "\n",
      "[11161 rows x 6680 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv('hateful/final_hateful_cleaned.csv')\n",
    "# Initialize the TF-IDF Vectorizer with min_df set to 5\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), min_df=2)\n",
    "\n",
    "# Fit and transform the cleaned comments\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for easier interpretation (optional)\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the resulting TF-IDF DataFrame\n",
    "print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 5.841138296258204e+26\n",
      "R-squared: -2.371113795954594e+26\n",
      "Top 10 Features Affecting Hatefulness (Score):\n",
      "          feature   coefficient\n",
      "665       baecker -7.743538e+14\n",
      "518    aufteilung -7.171560e+14\n",
      "93     abzuhalten -5.208846e+14\n",
      "284   angrenzende  5.157798e+14\n",
      "475    aufgeladen -4.933767e+14\n",
      "446            at  4.430320e+14\n",
      "319     anrichten  4.414303e+14\n",
      "442         asyls -4.276593e+14\n",
      "0              13 -3.799610e+14\n",
      "3155     jaehrige  3.799610e+14\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 2: Prepare target variable\n",
    "y = df['score']\n",
    "\n",
    "# Step 3: Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y, test_size=0.2, random_state=9999)\n",
    "\n",
    "# Step 4: Train a Linear Regression model using TF-IDF features as predictors\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions and evaluate the model\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) and R-squared for model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Step 6: Analyze Feature Importance (Coefficients)\n",
    "# Extract the coefficients from the linear model\n",
    "coefficients = linear_model.coef_\n",
    "\n",
    "# Combine feature names with their corresponding coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': tfidf_vectorizer.get_feature_names_out(),\n",
    "    'coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort features by absolute value of the coefficient to see which have the largest impact\n",
    "feature_importance['abs_coefficient'] = feature_importance['coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='abs_coefficient', ascending=False)\n",
    "\n",
    "# Display top 10 features affecting hatefulness the most\n",
    "print(\"Top 10 Features Affecting Hatefulness (Score):\")\n",
    "print(feature_importance.head(10)[['feature', 'coefficient']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) TF-IDF unigrams with COVARIATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv('hateful/final_hateful_cleaned.csv')\n",
    "# Initialize the TF-IDF Vectorizer with min_df set to 5\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), min_df=2)\n",
    "\n",
    "# Fit and transform the cleaned comments\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame for easier interpretation (optional)\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the resulting TF-IDF DataFrame\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Binary outcome for hateful speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('hateful/final_hateful_cleaned.csv')\n",
    "\n",
    "# Calculate the median of the 'score' variable\n",
    "median_score = df['score'].median()\n",
    "\n",
    "# Print the median to understand the threshold value\n",
    "print(f\"Median score: {median_score}\")\n",
    "\n",
    "# Create a new binary column 'hateful' based on the median threshold\n",
    "df['hateful'] = df['score'].apply(lambda x: 1 if x > median_score else 0)\n",
    "\n",
    "# Display the first few rows to check the new classification\n",
    "print(df[['score', 'hateful']].head())\n",
    "\n",
    "# Check the distribution of the 'hateful' variable\n",
    "class_distribution = df['hateful'].value_counts()\n",
    "\n",
    "# Print the count of each class\n",
    "print(\"Class distribution (count):\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Calculate the percentage distribution\n",
    "class_distribution_percent = df['hateful'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the percentage of each class\n",
    "print(\"\\nClass distribution (percentage):\")\n",
    "print(class_distribution_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/hateful/final_hateful_cleaned.csv')\n",
    "\n",
    "# Create a new binary column 'hateful' based on the threshold\n",
    "df['hateful'] = df['score'].apply(lambda x: 1 if x > 5 else 0)\n",
    "\n",
    "# Display the first few rows to check the new classification\n",
    "print(df[['score', 'hateful']].head())\n",
    "\n",
    "# Check the distribution of the 'hateful' variable\n",
    "class_distribution = df['hateful'].value_counts()\n",
    "\n",
    "# Print the count of each class\n",
    "print(\"Class distribution (count):\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Calculate the percentage distribution\n",
    "class_distribution_percent = df['hateful'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the percentage of each class\n",
    "print(\"\\nClass distribution (percentage):\")\n",
    "print(class_distribution_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) TF-IDF unigrams vs. trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Model Performance:\n",
      "Accuracy: 0.7604\n",
      "Precision: 0.4940\n",
      "Recall: 0.7091\n",
      "F1 Score: 0.5824\n",
      "\n",
      "Trigram Model Performance:\n",
      "Accuracy: 0.7412\n",
      "Precision: 0.3587\n",
      "Recall: 0.1255\n",
      "F1 Score: 0.1859\n",
      "Unigram Model Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.90      0.78      0.83      1707\n",
      "     Hateful       0.49      0.71      0.58       526\n",
      "\n",
      "    accuracy                           0.76      2233\n",
      "   macro avg       0.70      0.74      0.71      2233\n",
      "weighted avg       0.80      0.76      0.77      2233\n",
      "\n",
      "\n",
      "Unigram Model Confusion Matrix:\n",
      "[[1325  382]\n",
      " [ 153  373]]\n",
      "\n",
      "Trigram Model Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.78      0.93      0.85      1707\n",
      "     Hateful       0.36      0.13      0.19       526\n",
      "\n",
      "    accuracy                           0.74      2233\n",
      "   macro avg       0.57      0.53      0.52      2233\n",
      "weighted avg       0.68      0.74      0.69      2233\n",
      "\n",
      "\n",
      "Trigram Model Confusion Matrix:\n",
      "[[1589  118]\n",
      " [ 460   66]]\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: Generate TF-IDF with unigrams based on 'comment_cleaned'\n",
    "tfidf_vectorizer_uni = TfidfVectorizer(ngram_range=(1, 1), min_df=2)\n",
    "X_uni = tfidf_vectorizer_uni.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Step 2: Generate TF-IDF with trigrams based on 'comment_cleaned'\n",
    "tfidf_vectorizer_tri = TfidfVectorizer(ngram_range=(3, 3), min_df=2)\n",
    "X_tri = tfidf_vectorizer_tri.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Target variable\n",
    "y = df['hateful']\n",
    "\n",
    "# Split data into training and test sets for both unigram and trigram features\n",
    "X_train_uni, X_test_uni, y_train, y_test = train_test_split(X_uni, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "X_train_tri, X_test_tri, y_train, y_test = train_test_split(X_tri, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "\n",
    "# Step 3: Train logistic regression model with unigrams\n",
    "logistic_uni = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "logistic_uni.fit(X_train_uni, y_train)\n",
    "\n",
    "# Step 4: Train logistic regression model with trigrams\n",
    "logistic_tri = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "logistic_tri.fit(X_train_tri, y_train)\n",
    "\n",
    "# Step 5: Evaluate model performance on the test set for unigrams\n",
    "y_pred_uni = logistic_uni.predict(X_test_uni)\n",
    "accuracy_uni = accuracy_score(y_test, y_pred_uni)\n",
    "precision_uni = precision_score(y_test, y_pred_uni)\n",
    "recall_uni = recall_score(y_test, y_pred_uni)\n",
    "f1_uni = f1_score(y_test, y_pred_uni)\n",
    "\n",
    "print(\"Unigram Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_uni:.4f}\")\n",
    "print(f\"Precision: {precision_uni:.4f}\")\n",
    "print(f\"Recall: {recall_uni:.4f}\")\n",
    "print(f\"F1 Score: {f1_uni:.4f}\\n\")\n",
    "\n",
    "# Step 5: Evaluate model performance on the test set for trigrams\n",
    "y_pred_tri = logistic_tri.predict(X_test_tri)\n",
    "accuracy_tri = accuracy_score(y_test, y_pred_tri)\n",
    "precision_tri = precision_score(y_test, y_pred_tri)\n",
    "recall_tri = recall_score(y_test, y_pred_tri)\n",
    "f1_tri = f1_score(y_test, y_pred_tri)\n",
    "\n",
    "print(\"Trigram Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_tri:.4f}\")\n",
    "print(f\"Precision: {precision_tri:.4f}\")\n",
    "print(f\"Recall: {recall_tri:.4f}\")\n",
    "print(f\"F1 Score: {f1_tri:.4f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Unigram Model Evaluation\n",
    "print(\"Unigram Model Performance Report:\")\n",
    "print(classification_report(y_test, y_pred_uni, target_names=[\"Non-Hateful\", \"Hateful\"]))\n",
    "\n",
    "# Confusion Matrix for Unigram Model\n",
    "print(\"\\nUnigram Model Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_uni))\n",
    "\n",
    "# Trigram Model Evaluation\n",
    "print(\"\\nTrigram Model Performance Report:\")\n",
    "print(classification_report(y_test, y_pred_tri, target_names=[\"Non-Hateful\", \"Hateful\"]))\n",
    "\n",
    "# Confusion Matrix for Trigram Model\n",
    "print(\"\\nTrigram Model Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tri))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 3.69230769230769\n",
      "Unigram Model Performance:\n",
      "Accuracy: 0.7206\n",
      "Precision: 0.7135\n",
      "Recall: 0.7366\n",
      "F1 Score: 0.7249\n",
      "\n",
      "Trigram Model Performance:\n",
      "Accuracy: 0.5817\n",
      "Precision: 0.5512\n",
      "Recall: 0.8772\n",
      "F1 Score: 0.6770\n",
      "Unigram Model Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.73      0.70      0.72      1117\n",
      "     Hateful       0.71      0.74      0.72      1116\n",
      "\n",
      "    accuracy                           0.72      2233\n",
      "   macro avg       0.72      0.72      0.72      2233\n",
      "weighted avg       0.72      0.72      0.72      2233\n",
      "\n",
      "\n",
      "Unigram Model Confusion Matrix:\n",
      "[[787 330]\n",
      " [294 822]]\n",
      "\n",
      "Trigram Model Performance Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.70      0.29      0.41      1117\n",
      "     Hateful       0.55      0.88      0.68      1116\n",
      "\n",
      "    accuracy                           0.58      2233\n",
      "   macro avg       0.63      0.58      0.54      2233\n",
      "weighted avg       0.63      0.58      0.54      2233\n",
      "\n",
      "\n",
      "Trigram Model Confusion Matrix:\n",
      "[[320 797]\n",
      " [137 979]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('hateful/final_hateful_cleaned.csv')\n",
    "\n",
    "# Calculate the median of the 'score' variable\n",
    "median_score = df['score'].median()\n",
    "\n",
    "# Print the median to understand the threshold value\n",
    "print(f\"Median score: {median_score}\")\n",
    "\n",
    "# Create a new binary column 'hateful' based on the median threshold\n",
    "df['hateful'] = df['score'].apply(lambda x: 1 if x > median_score else 0)\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: Generate TF-IDF with unigrams based on 'comment_cleaned'\n",
    "tfidf_vectorizer_uni = TfidfVectorizer(ngram_range=(1, 1), min_df=2)\n",
    "X_uni = tfidf_vectorizer_uni.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Step 2: Generate TF-IDF with trigrams based on 'comment_cleaned'\n",
    "tfidf_vectorizer_tri = TfidfVectorizer(ngram_range=(3, 3), min_df=2)\n",
    "X_tri = tfidf_vectorizer_tri.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Target variable\n",
    "y = df['hateful']\n",
    "\n",
    "# Split data into training and test sets for both unigram and trigram features\n",
    "X_train_uni, X_test_uni, y_train, y_test = train_test_split(X_uni, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "X_train_tri, X_test_tri, y_train, y_test = train_test_split(X_tri, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "\n",
    "# Step 3: Train logistic regression model with unigrams\n",
    "logistic_uni = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "logistic_uni.fit(X_train_uni, y_train)\n",
    "\n",
    "# Step 4: Train logistic regression model with trigrams\n",
    "logistic_tri = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "logistic_tri.fit(X_train_tri, y_train)\n",
    "\n",
    "# Step 5: Evaluate model performance on the test set for unigrams\n",
    "y_pred_uni = logistic_uni.predict(X_test_uni)\n",
    "accuracy_uni = accuracy_score(y_test, y_pred_uni)\n",
    "precision_uni = precision_score(y_test, y_pred_uni)\n",
    "recall_uni = recall_score(y_test, y_pred_uni)\n",
    "f1_uni = f1_score(y_test, y_pred_uni)\n",
    "\n",
    "print(\"Unigram Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_uni:.4f}\")\n",
    "print(f\"Precision: {precision_uni:.4f}\")\n",
    "print(f\"Recall: {recall_uni:.4f}\")\n",
    "print(f\"F1 Score: {f1_uni:.4f}\\n\")\n",
    "\n",
    "# Step 5: Evaluate model performance on the test set for trigrams\n",
    "y_pred_tri = logistic_tri.predict(X_test_tri)\n",
    "accuracy_tri = accuracy_score(y_test, y_pred_tri)\n",
    "precision_tri = precision_score(y_test, y_pred_tri)\n",
    "recall_tri = recall_score(y_test, y_pred_tri)\n",
    "f1_tri = f1_score(y_test, y_pred_tri)\n",
    "\n",
    "print(\"Trigram Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_tri:.4f}\")\n",
    "print(f\"Precision: {precision_tri:.4f}\")\n",
    "print(f\"Recall: {recall_tri:.4f}\")\n",
    "print(f\"F1 Score: {f1_tri:.4f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Unigram Model Evaluation\n",
    "print(\"Unigram Model Performance Report:\")\n",
    "print(classification_report(y_test, y_pred_uni, target_names=[\"Non-Hateful\", \"Hateful\"]))\n",
    "\n",
    "# Confusion Matrix for Unigram Model\n",
    "print(\"\\nUnigram Model Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_uni))\n",
    "\n",
    "# Trigram Model Evaluation\n",
    "print(\"\\nTrigram Model Performance Report:\")\n",
    "print(classification_report(y_test, y_pred_tri, target_names=[\"Non-Hateful\", \"Hateful\"]))\n",
    "\n",
    "# Confusion Matrix for Trigram Model\n",
    "print(\"\\nTrigram Model Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tri))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Unigrams Performance:\n",
      "Accuracy: 0.6382\n",
      "Precision: 0.6405\n",
      "Recall: 0.6290\n",
      "F1 Score: 0.6347\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.64      0.65      0.64      1117\n",
      "     Hateful       0.64      0.63      0.63      1116\n",
      "\n",
      "    accuracy                           0.64      2233\n",
      "   macro avg       0.64      0.64      0.64      2233\n",
      "weighted avg       0.64      0.64      0.64      2233\n",
      "\n",
      "Confusion Matrix for Decision Tree with Unigrams:\n",
      "[[723 394]\n",
      " [414 702]]\n",
      "\n",
      "Decision Tree with Trigrams Performance:\n",
      "Accuracy: 0.5508\n",
      "Precision: 0.5299\n",
      "Recall: 0.8961\n",
      "F1 Score: 0.6660\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.66      0.21      0.31      1117\n",
      "     Hateful       0.53      0.90      0.67      1116\n",
      "\n",
      "    accuracy                           0.55      2233\n",
      "   macro avg       0.60      0.55      0.49      2233\n",
      "weighted avg       0.60      0.55      0.49      2233\n",
      "\n",
      "Confusion Matrix for Decision Tree with Trigrams:\n",
      "[[ 230  887]\n",
      " [ 116 1000]]\n",
      "\n",
      "Random Forest with Unigrams Performance:\n",
      "Accuracy: 0.7004\n",
      "Precision: 0.7049\n",
      "Recall: 0.6891\n",
      "F1 Score: 0.6969\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.70      0.71      0.70      1117\n",
      "     Hateful       0.70      0.69      0.70      1116\n",
      "\n",
      "    accuracy                           0.70      2233\n",
      "   macro avg       0.70      0.70      0.70      2233\n",
      "weighted avg       0.70      0.70      0.70      2233\n",
      "\n",
      "Confusion Matrix for Random Forest with Unigrams:\n",
      "[[795 322]\n",
      " [347 769]]\n",
      "\n",
      "Random Forest with Trigrams Performance:\n",
      "Accuracy: 0.5683\n",
      "Precision: 0.5415\n",
      "Recall: 0.8889\n",
      "F1 Score: 0.6730\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.69      0.25      0.36      1117\n",
      "     Hateful       0.54      0.89      0.67      1116\n",
      "\n",
      "    accuracy                           0.57      2233\n",
      "   macro avg       0.62      0.57      0.52      2233\n",
      "weighted avg       0.62      0.57      0.52      2233\n",
      "\n",
      "Confusion Matrix for Random Forest with Trigrams:\n",
      "[[277 840]\n",
      " [124 992]]\n",
      "\n",
      "SVM with Unigrams Performance:\n",
      "Accuracy: 0.7282\n",
      "Precision: 0.7188\n",
      "Recall: 0.7491\n",
      "F1 Score: 0.7337\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.74      0.71      0.72      1117\n",
      "     Hateful       0.72      0.75      0.73      1116\n",
      "\n",
      "    accuracy                           0.73      2233\n",
      "   macro avg       0.73      0.73      0.73      2233\n",
      "weighted avg       0.73      0.73      0.73      2233\n",
      "\n",
      "Confusion Matrix for SVM with Unigrams:\n",
      "[[790 327]\n",
      " [280 836]]\n",
      "\n",
      "SVM with Trigrams Performance:\n",
      "Accuracy: 0.5795\n",
      "Precision: 0.5576\n",
      "Recall: 0.7679\n",
      "F1 Score: 0.6461\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.63      0.39      0.48      1117\n",
      "     Hateful       0.56      0.77      0.65      1116\n",
      "\n",
      "    accuracy                           0.58      2233\n",
      "   macro avg       0.59      0.58      0.56      2233\n",
      "weighted avg       0.59      0.58      0.56      2233\n",
      "\n",
      "Confusion Matrix for SVM with Trigrams:\n",
      "[[437 680]\n",
      " [259 857]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pip install xgboost\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/hateful/final_hateful_cleaned.csv')\n",
    "\n",
    "# Calculate the median of the 'score' variable\n",
    "median_score = df['score'].median()\n",
    "df['hateful'] = df['score'].apply(lambda x: 1 if x > median_score else 0)\n",
    "\n",
    "# Step 1: Generate TF-IDF for unigrams and trigrams based on 'comment_cleaned'\n",
    "tfidf_vectorizer_uni = TfidfVectorizer(ngram_range=(1, 1), min_df=2)\n",
    "tfidf_vectorizer_tri = TfidfVectorizer(ngram_range=(3, 3), min_df=2)\n",
    "X_uni = tfidf_vectorizer_uni.fit_transform(df['comment_cleaned'])\n",
    "X_tri = tfidf_vectorizer_tri.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Target variable\n",
    "y = df['hateful']\n",
    "\n",
    "# Split data into training and test sets for both unigram and trigram features\n",
    "X_train_uni, X_test_uni, y_train, y_test = train_test_split(X_uni, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "X_train_tri, X_test_tri, _, _ = train_test_split(X_tri, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "\n",
    "# Define function to train model and evaluate metrics\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, feature_type):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model_name} with {feature_type} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Non-Hateful\", \"Hateful\"]))\n",
    "    print(f\"Confusion Matrix for {model_name} with {feature_type}:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "    \n",
    "# Define models\n",
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(class_weight=\"balanced\")),\n",
    "    (\"Random Forest\", RandomForestClassifier(class_weight=\"balanced\", random_state=1998)),\n",
    "    (\"SVM\", SVC(class_weight=\"balanced\", probability=True))\n",
    "]\n",
    "\n",
    "# Evaluate each model with unigrams and trigrams\n",
    "for model_name, model in models:\n",
    "    evaluate_model(model, X_train_uni, X_test_uni, y_train, y_test, model_name, \"Unigrams\")\n",
    "    evaluate_model(model, X_train_tri, X_test_tri, y_train, y_test, model_name, \"Trigrams\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across all classifiers, unigram models consistently outperform trigram models. Trigrams tend to over-predict hatefulness due to their specificity, resulting in low precision and high false positive rates. For social science applications, this suggests that unigrams capture enough context without being too specific, making them more reliable for identifying hatefulness in comments.\n",
    "\n",
    "The **SVM with unigrams** stands out as the best-performing model, with a strong balance between **precision, recall, and accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WITH METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Unigrams with Metadata Performance:\n",
      "Accuracy: 0.6279\n",
      "Precision: 0.6251\n",
      "Recall: 0.6380\n",
      "F1 Score: 0.6315\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.63      0.62      0.62      1117\n",
      "     Hateful       0.63      0.64      0.63      1116\n",
      "\n",
      "    accuracy                           0.63      2233\n",
      "   macro avg       0.63      0.63      0.63      2233\n",
      "weighted avg       0.63      0.63      0.63      2233\n",
      "\n",
      "Confusion Matrix for Decision Tree with Unigrams with Metadata:\n",
      "[[690 427]\n",
      " [404 712]]\n",
      "\n",
      "Decision Tree with Trigrams with Metadata Performance:\n",
      "Accuracy: 0.6090\n",
      "Precision: 0.5885\n",
      "Recall: 0.7240\n",
      "F1 Score: 0.6493\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.64      0.49      0.56      1117\n",
      "     Hateful       0.59      0.72      0.65      1116\n",
      "\n",
      "    accuracy                           0.61      2233\n",
      "   macro avg       0.62      0.61      0.60      2233\n",
      "weighted avg       0.62      0.61      0.60      2233\n",
      "\n",
      "Confusion Matrix for Decision Tree with Trigrams with Metadata:\n",
      "[[552 565]\n",
      " [308 808]]\n",
      "\n",
      "Random Forest with Unigrams with Metadata Performance:\n",
      "Accuracy: 0.7040\n",
      "Precision: 0.6949\n",
      "Recall: 0.7267\n",
      "F1 Score: 0.7105\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.71      0.68      0.70      1117\n",
      "     Hateful       0.69      0.73      0.71      1116\n",
      "\n",
      "    accuracy                           0.70      2233\n",
      "   macro avg       0.70      0.70      0.70      2233\n",
      "weighted avg       0.70      0.70      0.70      2233\n",
      "\n",
      "Confusion Matrix for Random Forest with Unigrams with Metadata:\n",
      "[[761 356]\n",
      " [305 811]]\n",
      "\n",
      "Random Forest with Trigrams with Metadata Performance:\n",
      "Accuracy: 0.6122\n",
      "Precision: 0.6036\n",
      "Recall: 0.6523\n",
      "F1 Score: 0.6270\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.62      0.57      0.60      1117\n",
      "     Hateful       0.60      0.65      0.63      1116\n",
      "\n",
      "    accuracy                           0.61      2233\n",
      "   macro avg       0.61      0.61      0.61      2233\n",
      "weighted avg       0.61      0.61      0.61      2233\n",
      "\n",
      "Confusion Matrix for Random Forest with Trigrams with Metadata:\n",
      "[[639 478]\n",
      " [388 728]]\n",
      "\n",
      "SVM with Unigrams with Metadata Performance:\n",
      "Accuracy: 0.7170\n",
      "Precision: 0.7017\n",
      "Recall: 0.7545\n",
      "F1 Score: 0.7271\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.73      0.68      0.71      1117\n",
      "     Hateful       0.70      0.75      0.73      1116\n",
      "\n",
      "    accuracy                           0.72      2233\n",
      "   macro avg       0.72      0.72      0.72      2233\n",
      "weighted avg       0.72      0.72      0.72      2233\n",
      "\n",
      "Confusion Matrix for SVM with Unigrams with Metadata:\n",
      "[[759 358]\n",
      " [274 842]]\n",
      "\n",
      "SVM with Trigrams with Metadata Performance:\n",
      "Accuracy: 0.6140\n",
      "Precision: 0.6084\n",
      "Recall: 0.6389\n",
      "F1 Score: 0.6233\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.62      0.59      0.60      1117\n",
      "     Hateful       0.61      0.64      0.62      1116\n",
      "\n",
      "    accuracy                           0.61      2233\n",
      "   macro avg       0.61      0.61      0.61      2233\n",
      "weighted avg       0.61      0.61      0.61      2233\n",
      "\n",
      "Confusion Matrix for SVM with Trigrams with Metadata:\n",
      "[[658 459]\n",
      " [403 713]]\n",
      "\n",
      "Logistic Regression with Unigrams with Metadata Performance:\n",
      "Accuracy: 0.7389\n",
      "Precision: 0.7323\n",
      "Recall: 0.7527\n",
      "F1 Score: 0.7424\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.75      0.73      0.74      1117\n",
      "     Hateful       0.73      0.75      0.74      1116\n",
      "\n",
      "    accuracy                           0.74      2233\n",
      "   macro avg       0.74      0.74      0.74      2233\n",
      "weighted avg       0.74      0.74      0.74      2233\n",
      "\n",
      "Confusion Matrix for Logistic Regression with Unigrams with Metadata:\n",
      "[[810 307]\n",
      " [276 840]]\n",
      "\n",
      "Logistic Regression with Trigrams with Metadata Performance:\n",
      "Accuracy: 0.6001\n",
      "Precision: 0.5960\n",
      "Recall: 0.6201\n",
      "F1 Score: 0.6078\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Hateful       0.60      0.58      0.59      1117\n",
      "     Hateful       0.60      0.62      0.61      1116\n",
      "\n",
      "    accuracy                           0.60      2233\n",
      "   macro avg       0.60      0.60      0.60      2233\n",
      "weighted avg       0.60      0.60      0.60      2233\n",
      "\n",
      "Confusion Matrix for Logistic Regression with Trigrams with Metadata:\n",
      "[[648 469]\n",
      " [424 692]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/hateful/final_hateful_cleaned.csv')\n",
    "\n",
    "# Calculate the median of the 'score' variable\n",
    "median_score = df['score'].median()\n",
    "df['hateful'] = df['score'].apply(lambda x: 1 if x > median_score else 0)\n",
    "\n",
    "# Step 1: Generate TF-IDF for unigrams and trigrams based on 'comment_cleaned'\n",
    "tfidf_vectorizer_uni = TfidfVectorizer(ngram_range=(1, 1), min_df=2)\n",
    "tfidf_vectorizer_tri = TfidfVectorizer(ngram_range=(3, 3), min_df=2)\n",
    "X_uni = tfidf_vectorizer_uni.fit_transform(df['comment_cleaned'])\n",
    "X_tri = tfidf_vectorizer_tri.fit_transform(df['comment_cleaned'])\n",
    "\n",
    "# Target variable\n",
    "y = df['hateful']\n",
    "\n",
    "# Select metadata features (sociodemographics and group)\n",
    "metadata = df[['group', 'state', 'education', 'employment', 'age', 'inhabitants', 'gender', 'East']]\n",
    "\n",
    "# Convert metadata to numerical values (if necessary, e.g., categorical encoding)\n",
    "metadata = pd.get_dummies(metadata, drop_first=True)\n",
    "\n",
    "# Convert metadata DataFrame to sparse format to concatenate with TF-IDF features\n",
    "from scipy.sparse import csr_matrix\n",
    "metadata_sparse = csr_matrix(metadata.values)\n",
    "\n",
    "# Combine TF-IDF features with metadata for both unigrams and trigrams\n",
    "X_uni_with_metadata = hstack([X_uni, metadata_sparse])\n",
    "X_tri_with_metadata = hstack([X_tri, metadata_sparse])\n",
    "\n",
    "# Split data into training and test sets for both unigram and trigram features\n",
    "X_train_uni, X_test_uni, y_train, y_test = train_test_split(X_uni_with_metadata, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "X_train_tri, X_test_tri, _, _ = train_test_split(X_tri_with_metadata, y, test_size=0.2, random_state=1998, stratify=y)\n",
    "\n",
    "# Define function to train model and evaluate metrics\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, feature_type):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model_name} with {feature_type} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Non-Hateful\", \"Hateful\"]))\n",
    "    print(f\"Confusion Matrix for {model_name} with {feature_type}:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "    \n",
    "# Define models\n",
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(class_weight=\"balanced\")),\n",
    "    (\"Random Forest\", RandomForestClassifier(class_weight=\"balanced\", random_state=1998)),\n",
    "    (\"SVM\", SVC(class_weight=\"balanced\", probability=True)),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, class_weight=\"balanced\"))\n",
    "]\n",
    "\n",
    "# Evaluate each model with unigrams and trigrams\n",
    "for model_name, model in models:\n",
    "    evaluate_model(model, X_train_uni, X_test_uni, y_train, y_test, model_name, \"Unigrams with Metadata\")\n",
    "    evaluate_model(model, X_train_tri, X_test_tri, y_train, y_test, model_name, \"Trigrams with Metadata\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (counterspeech)",
   "language": "python",
   "name": "counterspeech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
